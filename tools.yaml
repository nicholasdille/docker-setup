tools:

  - name: act
    version: 0.2.30
    check: ${binary} --version | cut -d' ' -f3
    needs:
    - docker
    tags:
    - development
    - testing
    - automation
    download:
    - url:
        x86_64: https://github.com/nektos/act/releases/download/v${version}/act_Linux_${arch}.tar.gz
        aarch64: https://github.com/nektos/act/releases/download/v${version}/act_Linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - act

  - name: arkade
    version: 0.8.28
    check: ${binary} version | grep "version" | cut -d' ' -f2
    tags:
    - k8s
    - kubernetes
    - package
    - management
    download:
    - url:
        x86_64: https://github.com/alexellis/arkade/releases/download/${version}/arkade
        aarch64: https://github.com/alexellis/arkade/releases/download/${version}/arkade-arm64
      type: executable
    post_install: |
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: bin
    version: 0.15.1
    check: ${binary} --version | grep ^bin | cut -d' ' -f3
    tags:
    - management
    download:
    - url:
        x86_64: https://github.com/marcosnils/bin/releases/download/v${version}/bin_${version}_Linux_${arch}
        aarch64: https://github.com/marcosnils/bin/releases/download/v${version}/bin_${version}_Linux_${alt_arch}
      type: executable

  - name: buildah
    version: 1.26.4
    check: ${binary} --version | cut -d' ' -f3
    needs:
    - runc
    - cni
    tags:
    - build
    - redhat
    - oci
    download:
    - url:
        x86_64: https://github.com/nicholasdille/buildah-static/releases/download/v${version}/buildah-${alt_arch}.tar.gz
      type: tarball
      path: ${target}

  - name: buildg
    version: 0.3.0
    check: ${binary} version | cut -d' ' -f2 | tr -d v
    needs:
    - runc
    - cni
    tags:
    - build
    - debug
    - oci
    download:
    - url: https://github.com/ktock/buildg/releases/download/v${version}/buildg-v${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - ./buildg
      - ./buildg.sh

  - name: buildkit
    version: 0.10.3
    binary: buildkitd
    tags:
    - docker
    - build
    - oci
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    download:
    - url: https://github.com/moby/buildkit/releases/download/v${version}/buildkit-v${version}.linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      strip: 1
    - url: https://github.com/moby/buildkit/raw/v${version}/examples/systemd/system/buildkit.service
      type: file
      path: ${prefix}/etc/systemd/system/buildkit.service
    - url: https://github.com/moby/buildkit/raw/v${version}/examples/systemd/system/buildkit.socket
      type: file
      path: ${prefix}/etc/systemd/system/buildkit.socket
    files:
    - path: ${prefix}/etc/init.d/buildkit
      content: |
        #!/bin/sh
        set -e

        ### BEGIN INIT INFO
        # Provides:           buildkit
        # Required-Start:     $syslog $remote_fs
        # Required-Stop:      $syslog $remote_fs
        # Should-Start:       cgroupfs-mount cgroup-lite
        # Should-Stop:        cgroupfs-mount cgroup-lite
        # Default-Start:      2 3 4 5
        # Default-Stop:       0 1 6
        # Short-Description:  Create lightweight, portable, self-sufficient containers.
        # Description:
        #  Docker is an open-source project to easily create lightweight, portable,
        #  self-sufficient containers from any application. The same container that a
        #  developer builds and tests on a laptop can run at scale, in production, on
        #  VMs, bare metal, OpenStack clusters, public clouds and more.
        ### END INIT INFO

        export PATH=/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/sbin:/usr/local/bin

        BASE=buildkit

        # modify these in /etc/default/$BASE (/etc/default/buildkit)
        BUILDKIT=/usr/local/bin/buildkitd
        # This is the pid file created/managed by start-stop-daemon
        BUILDKIT_SSD_PIDFILE=/var/run/$BASE-ssd.pid
        BUILDKIT_LOGFILE=/var/log/$BASE.log
        BUILDKIT_DESC="BuildKit"

        # Get lsb functions
        . /lib/lsb/init-functions

        if [ -f /etc/default/$BASE ]; then
          . /etc/default/$BASE
        fi

        # Check buildkit is present
        if [ ! -x $BUILDKIT ]; then
          log_failure_msg "$BUILDKIT not present or not executable"
          exit 1
        fi

        check_init() {
          # see also init_is_upstart in /lib/lsb/init-functions (which isn't available in Ubuntu 12.04, or we'd use it directly)
          if [ -x /sbin/initctl ] && /sbin/initctl version 2> /dev/null | grep -q upstart; then
            log_failure_msg "$BUILDKIT_DESC is managed via upstart, try using service $BASE $1"
            exit 1
          fi
        }

        fail_unless_root() {
          if [ "$(id -u)" != '0' ]; then
            log_failure_msg "$BUILDKIT_DESC must be run as root"
            exit 1
          fi
        }

        cgroupfs_mount() {
          # see also https://github.com/tianon/cgroupfs-mount/blob/master/cgroupfs-mount
          if grep -v '^#' /etc/fstab | grep -q cgroup \
            || [ ! -e /proc/cgroups ] \
            || [ ! -d /sys/fs/cgroup ]; then
            return
          fi
          if ! mountpoint -q /sys/fs/cgroup; then
            mount -t tmpfs -o uid=0,gid=0,mode=0755 cgroup /sys/fs/cgroup
          fi
          (
            cd /sys/fs/cgroup
            for sys in $(awk '!/^#/ { if ($4 == 1) print $1 }' /proc/cgroups); do
              mkdir -p $sys
              if ! mountpoint -q $sys; then
                if ! mount -n -t cgroup -o $sys cgroup $sys; then
                  rmdir $sys || true
                fi
              fi
            done
          )
        }

        case "$1" in
          start)
            check_init

            fail_unless_root

            cgroupfs_mount

            touch "$BUILDKIT_LOGFILE"

            ulimit -n 1048576

            # Having non-zero limits causes performance problems due to accounting overhead
            # in the kernel. We recommend using cgroups to do container-local accounting.
            if [ "$BASH" ]; then
              ulimit -u unlimited
            else
              ulimit -p unlimited
            fi

            log_begin_msg "Starting $BUILDKIT_DESC: $BASE"
            start-stop-daemon --start --background \
              --no-close \
              --exec "$BUILDKIT" \
              --pidfile "$BUILDKIT_SSD_PIDFILE" \
              --make-pidfile \
              -- \
              >> "$BUILDKIT_LOGFILE" 2>&1
            log_end_msg $?
            ;;

          stop)
            check_init
            fail_unless_root
            if [ -f "$BUILDKIT_SSD_PIDFILE" ]; then
              log_begin_msg "Stopping $BUILDKIT_DESC: $BASE"
              start-stop-daemon --stop --pidfile "$BUILDKIT_SSD_PIDFILE" --retry 10
              log_end_msg $?
            else
              log_warning_msg "Docker already stopped - file $BUILDKIT_SSD_PIDFILE not found."
            fi
            ;;

          restart)
            check_init
            fail_unless_root
            buildkit_pid=$(cat "$BUILDKIT_SSD_PIDFILE" 2> /dev/null)
            [ -n "$buildkit_pid" ] \
              && ps -p $buildkit_pid > /dev/null 2>&1 \
              && $0 stop
            $0 start
            ;;

          force-reload)
            check_init
            fail_unless_root
            $0 restart
            ;;

          status)
            check_init
            status_of_proc -p "$BUILDKIT_SSD_PIDFILE" "$BUILDKIT" "$BUILDKIT_DESC"
            ;;

          *)
            echo "Usage: service buildkit {start|stop|restart|status}"
            exit 1
            ;;
        esac
    post_install: |
      echo "Install systemd units"
      sed -i "s|ExecStart=/usr/local/bin/buildkitd|ExecStart=${target}/bin/buildkitd|" "${prefix}/etc/systemd/system/buildkit.service"
      echo "Install init script"
      sed -i "s|/usr/local/bin/buildkitd|${relative_target}/bin/buildkitd|" "${prefix}/etc/init.d/buildkit"
      chmod +x "${prefix}/etc/init.d/buildkit"
      if test -z "${prefix}" && has_systemd; then
          echo "Reload systemd"
          systemctl daemon-reload
      fi

  - name: buildx
    version: 0.8.2
    binary: ${target}/libexec/docker/cli-plugins/docker-buildx
    check: ${binary} version | cut -d' ' -f2 | tr -d v
    needs:
    - docker
    tags:
    - default
    - docker
    - plugin
    download:
    - url: https://github.com/docker/buildx/releases/download/v${version}/buildx-v${version}.linux-${alt_arch}
      type: executable
    post_install: |
      cat >"${prefix}/etc/profile.d/docker-buildx-install" <<EOF
      #!/bin/bash

      cat <<< "$(jq '. * {"aliases": {"builder": "buildx"}}' "${HOME}/.docker/config.json")" >"${HOME}/.docker/config.json"
      EOF
      echo "Register buildx as default builder"
      docker buildx install
      if docker_is_running || tool_will_be_installed "docker"; then
          echo "Wait for Docker daemon to start"
          wait_for_docker
          echo "Enable multi-platform builds"
          "${target}/bin/docker" container run --privileged --rm tonistiigi/binfmt --install all
      fi

  - name: bypass4netns
    version: 0.2.2
    needs:
    - docker
    - slirp4netns
    tags:
    - rootless
    - network
    dockerfile: |
      FROM golang:${go_version}
      RUN apt-get update \
       && apt-get -y install \
              libseccomp-dev
    install: |
      docker_run \
          --workdir /go/src/github.com/rootless-containers/bypass4netns \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/rootless-containers/bypass4netns .
      make static
      cp bypass4netns{,d} /target/bin/
      EOF

  - name: cas
    version: 1.0.2
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    tags:
    - security
    download:
    - url:
        x86_64: https://github.com/codenotary/cas/releases/download/v${version}/cas-v${version}-linux-${alt_arch}-static
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: cinf
    version: 0.6.0
    tags:
    - kernel
    - cgroups
    - caps
    download:
    - url: https://github.com/mhausenblas/cinf/releases/download/v${version}/cinf_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - cinf

  - name: clusterawsadm
    version: 1.4.1
    check: ${binary} version --output short | tr -d v
    tags:
    - k8s
    - kubernetes
    - cloud
    download:
    - url: https://github.com/kubernetes-sigs/cluster-api-provider-aws/releases/download/v${version}/clusterawsadm-linux-amd64
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: clusterctl
    version: 1.2.0
    check: ${binary} version --output short | tr -d v
    tags:
    - k8s
    - kubernetes
    download:
    - url: https://github.com/kubernetes-sigs/cluster-api/releases/download/v${version}/clusterctl-linux-${alt_arch}
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: cni
    version: 1.1.1
    binary: ${target}/libexec/cni/loopback
    check: ${binary} 2>&1 | cut -d' ' -f4 | tr -d v
    tags:
    - k8s
    - kubernetes
    - network
    download:
    - url: https://github.com/containernetworking/plugins/releases/download/v${version}/cni-plugins-linux-${alt_arch}-v${version}.tgz
      type: tarball
      path: ${target}/libexec/cni

  - name: cnitool
    version: 1.1.2
    needs:
    - docker
    tags:
    - k8s
    - kubernetes
    - network
    dockerfile: |
      FROM golang:${go_version}
    install: |
      docker_run \
          --workdir /go/src/github.com/containernetworking/cni \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/containernetworking/cni .
      cd cnitool
      CGO_ENABLED=0 go build -ldflags '-s -w' -o cnitool .
      cp cnitool /target/bin/
      EOF

  - name: cni-isolation
    version: 0.0.4
    binary: ${target}/libexec/cni/isolation
    tags:
    - k8s
    - kubernetes
    - network
    download:
    - url: https://github.com/AkihiroSuda/cni-isolation/releases/download/v${version}/cni-isolation-${alt_arch}.tgz
      type: tarball
      path: ${target}/libexec/cni

  - name: conmon
    version: 2.1.3
    check: ${binary} --version | grep "conmon version" | cut -d' ' -f3
    needs:
    - shortnames
    tags:
    - redhat
    - runtime
    download:
    - url: https://github.com/nicholasdille/conmon-static/releases/download/v${version}/conmon-${alt_arch}.tar.gz
      type: tarball
      path: ${target}
    files:
    - path: ${prefix}/etc/containers/registries.d/default.yaml
      content: |
        default-docker:
          sigstore-staging: file:///var/lib/containers/sigstore
    - path: ${prefix}/etc/containers/policy.json
      content: |
        {
          "default": [
            {
              "type": "insecureAcceptAnything"
            }
          ],
          "transports": {
            "docker-daemon": {
              "": [
                {
                  "type":"insecureAcceptAnything"
                }
              ]
            }
          }
        }
    - path: ${prefix}/etc/containers/registries.json
      content: |
        unqualified-search-registries = ["docker.io", "quay.io"]
    - path: ${prefix}/etc/containers/storage.conf
      content: |
        [storage]
        driver = "overlay"
        runroot = "/run/containers/storage"
        graphroot = "/var/lib/containers/storage"

        [storage.options]
        additionalimagestores = [
        ]

        [storage.options.overlay]
        mountopt = "nodev,metacopy=on"

        [storage.options.thinpool]

  - name: containerd
    version: 1.6.6
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    needs:
    - runc
    - cni
    - go-md2man
    - crictl
    tags:
    - runtime
    - containerd
    - cri
    download:
    - url: https://github.com/containerd/containerd/releases/download/v${version}/containerd-${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}
    - url: https://github.com/containerd/containerd/raw/v${version}/containerd.service
      type: file
      path: ${prefix}/etc/systemd/system/containerd.service
    - url: https://github.com/containerd/containerd/raw/v${version}/docs/man/containerd-config.8.md
      type: file
      path: ${target}/share/man/man8/containerd-config.8.md
    - url: https://github.com/containerd/containerd/raw/v${version}/docs/man/containerd-config.toml.5.md
      type: file
      path: ${target}/share/man/man5/containerd-config.toml.5.md
    files:
    - path: ${prefix}/etc/containerd/conf.d/oom-score-adjust.toml
      content: |
        [Service]
        # Decreases the likelihood that containerd is killed due to memory
        # pressure.
        #
        # Please see the following link for more information about the
        # OOMScoreAdjust configuration property:
        # https://www.freedesktop.org/software/systemd/man/systemd.exec.html#OOMScoreAdjust=
        OOMScoreAdjust=-999
    - path: ${prefix}/etc/containerd/conf.d/max-tasks.toml
      content: |
        [Service]
        # Do not limit the number of tasks that can be spawned by containerd
        TasksMax=infinity
    - path: ${prefix}/etc/cni/net.d/10-containerd-net.conflist
      content: |
        {
          "cniVersion": "1.0.0",
          "name": "containerd-net",
          "plugins": [
            {
              "type": "bridge",
              "bridge": "cni0",
              "isGateway": true,
              "ipMasq": true,
              "promiscMode": true,
              "ipam": {
                "type": "host-local",
                "ranges": [
                  [{
                    "subnet": "172.129.0.0/16"
                  }]
                ],
                "routes": [
                  { "dst": "0.0.0.0/0" },
                  { "dst": "::/0" }
                ]
              }
            },
            {
              "type": "portmap",
              "capabilities": {"portMappings": true}
            }
          ]
        }
    - path: ${prefix}/etc/init.d/containerd
      content: |
        #!/bin/sh
        set -e

        ### BEGIN INIT INFO
        # Provides:           containerd
        # Required-Start:     $syslog $remote_fs
        # Required-Stop:      $syslog $remote_fs
        # Should-Start:       cgroupfs-mount cgroup-lite
        # Should-Stop:        cgroupfs-mount cgroup-lite
        # Default-Start:      2 3 4 5
        # Default-Stop:       0 1 6
        # Short-Description:  Create lightweight, portable, self-sufficient containers.
        # Description:
        #  Docker is an open-source project to easily create lightweight, portable,
        #  self-sufficient containers from any application. The same container that a
        #  developer builds and tests on a laptop can run at scale, in production, on
        #  VMs, bare metal, OpenStack clusters, public clouds and more.
        ### END INIT INFO

        export PATH=/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/sbin:/usr/local/bin

        BASE=containerd

        # modify these in /etc/default/$BASE (/etc/default/containerd)
        CONTAINERD=/usr/local/bin/containerd
        # This is the pid file created/managed by start-stop-daemon
        CONTAINERD_SSD_PIDFILE=/var/run/$BASE-ssd.pid
        CONTAINERD_LOGFILE=/var/log/$BASE.log
        CONTAINERD_DESC="containerd"

        # Get lsb functions
        . /lib/lsb/init-functions

        if [ -f /etc/default/$BASE ]; then
          . /etc/default/$BASE
        fi

        # Check containerd is present
        if [ ! -x $CONTAINERD ]; then
          log_failure_msg "$CONTAINERD not present or not executable"
          exit 1
        fi

        check_init() {
          # see also init_is_upstart in /lib/lsb/init-functions (which isn't available in Ubuntu 12.04, or we'd use it directly)
          if [ -x /sbin/initctl ] && /sbin/initctl version 2> /dev/null | grep -q upstart; then
            log_failure_msg "$CONTAINERD_DESC is managed via upstart, try using service $BASE $1"
            exit 1
          fi
        }

        fail_unless_root() {
          if [ "$(id -u)" != '0' ]; then
            log_failure_msg "$CONTAINERD_DESC must be run as root"
            exit 1
          fi
        }

        cgroupfs_mount() {
          # see also https://github.com/tianon/cgroupfs-mount/blob/master/cgroupfs-mount
          if grep -v '^#' /etc/fstab | grep -q cgroup \
            || [ ! -e /proc/cgroups ] \
            || [ ! -d /sys/fs/cgroup ]; then
            return
          fi
          if ! mountpoint -q /sys/fs/cgroup; then
            mount -t tmpfs -o uid=0,gid=0,mode=0755 cgroup /sys/fs/cgroup
          fi
          (
            cd /sys/fs/cgroup
            for sys in $(awk '!/^#/ { if ($4 == 1) print $1 }' /proc/cgroups); do
              mkdir -p $sys
              if ! mountpoint -q $sys; then
                if ! mount -n -t cgroup -o $sys cgroup $sys; then
                  rmdir $sys || true
                fi
              fi
            done
          )
        }

        case "$1" in
          start)
            check_init

            fail_unless_root

            #cgroupfs_mount

            touch "$CONTAINERD_LOGFILE"

            ulimit -n 1048576

            # Having non-zero limits causes performance problems due to accounting overhead
            # in the kernel. We recommend using cgroups to do container-local accounting.
            if [ "$BASH" ]; then
              ulimit -u unlimited
            else
              ulimit -p unlimited
            fi

            log_begin_msg "Starting $CONTAINERD_DESC: $BASE"
            start-stop-daemon --start --background \
              --no-close \
              --exec "$CONTAINERD" \
              --pidfile "$CONTAINERD_SSD_PIDFILE" \
              --make-pidfile \
              -- \
              >> "$CONTAINERD_LOGFILE" 2>&1
            log_end_msg $?
            ;;

          stop)
            check_init
            fail_unless_root
            if [ -f "$CONTAINERD_SSD_PIDFILE" ]; then
              log_begin_msg "Stopping $CONTAINERD_DESC: $BASE"
              start-stop-daemon --stop --pidfile "$CONTAINERD_SSD_PIDFILE" --retry 10
              log_end_msg $?
            else
              log_warning_msg "Docker already stopped - file $CONTAINERD_SSD_PIDFILE not found."
            fi
            ;;

          restart)
            check_init
            fail_unless_root
            containerd_pid=$(cat "$CONTAINERD_SSD_PIDFILE" 2> /dev/null)
            [ -n "$containerd_pid" ] \
              && ps -p $containerd_pid > /dev/null 2>&1 \
              && $0 stop
            $0 start
            ;;

          force-reload)
            check_init
            fail_unless_root
            $0 restart
            ;;

          status)
            check_init
            status_of_proc -p "$CONTAINERD_SSD_PIDFILE" "$CONTAINERD" "$CONTAINERD_DESC"
            ;;

          *)
            echo "Usage: service containerd {start|stop|restart|status}"
            exit 1
            ;;
        esac
    post_install: |
      chmod +x "${prefix}/etc/init.d/containerd"
      go-md2man -in "${target}/share/man/man8/containerd-config.8.md" -out "${target}/share/man/man8/containerd-config.8"
      go-md2man -in "${target}/share/man/man5/containerd-config.toml.5.md" -out "${target}/share/man/man5/containerd-config.toml.5"
      rm \
          "${target}/share/man/man8/containerd-config.8.md" \
          "${target}/share/man/man5/containerd-config.toml.5.md"
      if ! test -f "${prefix}/etc/containerd/config.toml"; then
          echo "Adding default configuration"
          mkdir -p "${prefix}/etc/containerd/conf.d" "${prefix}/etc/containerd/certs.d"
          "${target}/bin/containerd" config default >"${prefix}/etc/containerd/config.toml"
          sed -i "s|/opt/cni/bin|${relative_target}/libexec/cni|" "${prefix}/etc/containerd/config.toml"
          sed -i 's|imports = []|imports = ["/etc/containerd/conf.d/*.toml"]|' "${prefix}/etc/containerd/config.toml"
          sed 's|config_path = ""|config_path = "/etc/containerd/certs.d"|' "${prefix}/etc/containerd/config.toml"
      fi
      if test -f "${prefix}/etc/crictl.yaml"; then
          echo "Fixing configuration for cticrl"
          ENDPOINT=unix:///run/containerd/containerd.sock
          sed -i \
              "s|#runtime-endpoint: YOUR-CHOICE|runtime-endpoint: ${ENDPOINT}|; s|#image-endpoint: YOUR-CHOICE|image-endpoint: ${ENDPOINT}|" \
              "${prefix}/etc/crictl.yaml"
      fi
      if test -f "${prefix}/etc/group"; then
          echo "Create group (@ ${SECONDS} seconds)"
          groupadd --prefix "${prefix}" --system --force containerd
      fi
      echo "Install systemd unit"
      sed -i "s|ExecStart=/usr/local/bin/containerd|ExecStart=${relative_target}/bin/containerd|" "${prefix}/etc/systemd/system/containerd.service"
      if test -z "${prefix}"; then
          if has_systemd; then
              echo "Reload systemd"
              systemctl daemon-reload
          fi
      fi

  - name: containerssh
    version: 0.4.1
    tags:
    - security
    download:
    - url: https://github.com/ContainerSSH/ContainerSSH/releases/download/v${version}/containerssh_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - containerssh
      - containerssh-auditlog-decoder
      - containerssh-testauthconfigserver

  - name: cosign
    version: 1.10.0
    check: ${binary} version | grep GitVersion | tr -s ' ' | cut -d' ' -f2 | tr -d v
    needs:
    - docker
    tags:
    - security
    download:
    - url: https://github.com/sigstore/cosign/releases/download/v${version}/cosign-linux-${alt_arch}
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: crane
    version: 0.11.0
    check: ${binary} version
    tags:
    - registry
    - image
    - oci
    download:
    - url: https://github.com/google/go-containerregistry/releases/download/v${version}/go-containerregistry_Linux_${arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - crane
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: cri-dockerd
    version: 0.2.4
    check: ${binary} --version 2>&1 | cut -d' ' -f2
    needs:
    - docker
    - crictl
    tags:
    - docker
    - k8s
    - kubernetes
    - runtime
    - cri
    download:
    - url: https://github.com/Mirantis/cri-dockerd/releases/download/v${version}/cri-dockerd-${version}.${alt_arch}.tgz
      type: tarball
      path: ${target}/bin
      files:
      - cri-dockerd
    post_install: |
      if test -f "${prefix}/etc/crictl.yaml"; then
          echo "Fixing configuration for cticrl"
          ENDPOINT=unix:///var/run/cri-dockerd.sock
          sed -i \
              "s|#runtime-endpoint: YOUR-CHOICE|runtime-endpoint: ${ENDPOINT}|; s|#image-endpoint: YOUR-CHOICE|image-endpoint: ${ENDPOINT}|" \
              "${prefix}/etc/crictl.yaml"
      fi

  - name: cri-o
    version: 1.24.1
    check: ${binary} --version | grep ^Version | tr -s ' ' | cut -d' ' -f2
    needs:
    - runc
    - cni
    - go-md2man
    - crictl
    tags:
    - redhat
    - runtime
    - oci
    - cri
    download:
    - url: https://github.com/cri-o/cri-o/releases/download/v${version}/cri-o.${alt_arch}.v${version}.tar.gz
      type: tarball
      path: ${target}
      strip: 1
      files:
      - cri-o/bin/crio
      - cri-o/bin/crio-status
    - url: https://github.com/cri-o/cri-o/raw/v${version}/docs/crio.8.md
      type: file
      path: ${target}/share/man/man8/crio.8.md
    - url: https://github.com/cri-o/cri-o/raw/v${version}/docs/crio-status.8.md
      type: file
      path: ${target}/share/man/man8/crio-status.8.md
    - url: https://github.com/cri-o/cri-o/raw/v${version}/docs/crio.conf.5.md
      type: file
      path: ${target}/share/man/man5/crio.conf.5.md
    - url: https://github.com/cri-o/cri-o/raw/v${version}/docs/crio.conf.d.5.md
      type: file
      path: ${target}/share/man/man5/crio.conf.d.5.md
    - url: https://github.com/cri-o/cri-o/raw/v${version}/completions/bash/crio
      type: file
      path: ${target}/share/bash-completion/completions/crio
    - url: https://github.com/cri-o/cri-o/raw/v${version}/completions/bash/crio-status
      type: file
      path: ${target}/share/bash-completion/completions/crio-status
    - url: https://github.com/cri-o/cri-o/raw/v${version}/completions/fish/crio.fish
      type: file
      path: ${target}/share/fish/vendor_completions.d/crio.fish
    - url: https://github.com/cri-o/cri-o/raw/v${version}/completions/fish/crio-status.fish
      type: file
      path: ${target}/share/fish/vendor_completions.d/crio-status.fish
    - url: https://github.com/cri-o/cri-o/raw/v${version}/completions/zsh/_crio
      type: file
      path: ${target}/share/zsh/vendor-completions/_crio
    - url: https://github.com/cri-o/cri-o/raw/v${version}/completions/zsh/_crio-status
      type: file
      path: ${target}/share/zsh/vendor-completions/_crio-status
    - url: https://github.com/cri-o/cri-o/raw/v${version}/contrib/systemd/crio.service
      type: file
      path: ${prefix}/etc/systemd/system/crio.service
    - url: https://github.com/cri-o/cri-o/raw/v${version}/contrib/systemd/crio-wipe.service
      type: file
      path: ${prefix}/etc/systemd/system/crio-wipe.service
    - url: https://github.com/cri-o/cri-o/raw/v${version}/contrib/sysconfig/crio
      type: file
      path: ${prefix}/etc/sysconfig/crio
    - url: https://github.com/cri-o/cri-o/raw/v${version}/contrib/cni/10-crio-bridge.conf
      type: file
      path: ${prefix}/etc/cni/net.d/10-crio-bridge.conf
    - url: https://github.com/cri-o/cri-o/raw/v${version}/contrib/cni/11-crio-ipv4-bridge.conf
      type: file
      path: ${prefix}/etc/cni/net.d/11-crio-ipv4-bridge.conf
    - url: https://github.com/cri-o/cri-o/raw/v${version}/contrib/cni/99-loopback.conf
      type: file
      path: ${prefix}/etc/cni/net.d/99-loopback.conf
    files:
    - path: ${prefix}/etc/crio.conf
      content: |
        # The CRI-O configuration file specifies all of the available configuration
        # options and command-line flags for the crio(8) OCI Kubernetes Container Runtime
        # daemon, but in a TOML format that can be more easily modified and versioned.
        #
        # Please refer to crio.conf(5) for details of all configuration options.

        # CRI-O supports partial configuration reload during runtime, which can be
        # done by sending SIGHUP to the running process. Currently supported options
        # are explicitly mentioned with: 'This option supports live configuration
        # reload'.

        # CRI-O reads its storage defaults from the containers-storage.conf(5) file
        # located at /etc/containers/storage.conf. Modify this storage configuration if
        # you want to change the system's defaults. If you want to modify storage just
        # for CRI-O, you can change the storage configuration options here.
        [crio]

        # Path to the "root directory". CRI-O stores all of its data, including
        # containers images, in this directory.
        # root = "/home/runner/.local/share/containers/storage"

        # Path to the "run directory". CRI-O stores all of its state in this directory.
        # runroot = "/tmp/containers-user-1001/containers"

        # Storage driver used to manage the storage of images and containers. Please
        # refer to containers-storage.conf(5) to see all available storage drivers.
        # storage_driver = "overlay"

        # List to pass options to the storage driver. Please refer to
        # containers-storage.conf(5) to see all available storage options.
        # storage_option = [
        # 	"overlay.mount_program=/usr/bin/fuse-overlayfs",
        # ]

        # The default log directory where all logs will go unless directly specified by
        # the kubelet. The log directory specified must be an absolute directory.
        # log_dir = "/var/log/crio/pods"

        # Location for CRI-O to lay down the temporary version file.
        # It is used to check if crio wipe should wipe containers, which should
        # always happen on a node reboot
        # version_file = "/var/run/crio/version"

        # Location for CRI-O to lay down the persistent version file.
        # It is used to check if crio wipe should wipe images, which should
        # only happen when CRI-O has been upgraded
        # version_file_persist = "/var/lib/crio/version"

        # InternalWipe is whether CRI-O should wipe containers and images after a reboot when the server starts.
        # If set to false, one must use the external command 'crio wipe' to wipe the containers and images in these situations.
        # internal_wipe = true

        # Location for CRI-O to lay down the clean shutdown file.
        # It is used to check whether crio had time to sync before shutting down.
        # If not found, crio wipe will clear the storage directory.
        # clean_shutdown_file = "/var/lib/crio/clean.shutdown"

        # The crio.api table contains settings for the kubelet/gRPC interface.
        [crio.api]

        # Path to AF_LOCAL socket on which CRI-O will listen.
        # listen = "/var/run/crio/crio.sock"

        # IP address on which the stream server will listen.
        # stream_address = "127.0.0.1"

        # The port on which the stream server will listen. If the port is set to "0", then
        # CRI-O will allocate a random free port number.
        # stream_port = "0"

        # Enable encrypted TLS transport of the stream server.
        # stream_enable_tls = false

        # Length of time until open streams terminate due to lack of activity
        # stream_idle_timeout = ""

        # Path to the x509 certificate file used to serve the encrypted stream. This
        # file can change, and CRI-O will automatically pick up the changes within 5
        # minutes.
        # stream_tls_cert = ""

        # Path to the key file used to serve the encrypted stream. This file can
        # change and CRI-O will automatically pick up the changes within 5 minutes.
        # stream_tls_key = ""

        # Path to the x509 CA(s) file used to verify and authenticate client
        # communication with the encrypted stream. This file can change and CRI-O will
        # automatically pick up the changes within 5 minutes.
        # stream_tls_ca = ""

        # Maximum grpc send message size in bytes. If not set or <=0, then CRI-O will default to 16 * 1024 * 1024.
        # grpc_max_send_msg_size = 83886080

        # Maximum grpc receive message size. If not set or <= 0, then CRI-O will default to 16 * 1024 * 1024.
        # grpc_max_recv_msg_size = 83886080

        # The crio.runtime table contains settings pertaining to the OCI runtime used
        # and options for how to set up and manage the OCI runtime.
        [crio.runtime]

        # A list of ulimits to be set in containers by default, specified as
        # "<ulimit name>=<soft limit>:<hard limit>", for example:
        # "nofile=1024:2048"
        # If nothing is set here, settings will be inherited from the CRI-O daemon
        # default_ulimits = [
        # ]

        # If true, the runtime will not use pivot_root, but instead use MS_MOVE.
        # no_pivot = false

        # decryption_keys_path is the path where the keys required for
        # image decryption are stored. This option supports live configuration reload.
        # decryption_keys_path = "/etc/crio/keys/"

        # Path to the conmon binary, used for monitoring the OCI runtime.
        # Will be searched for using $PATH if empty.
        # This option is currently deprecated, and will be replaced with RuntimeHandler.MonitorEnv.
        # conmon = ""

        # Cgroup setting for conmon
        # This option is currently deprecated, and will be replaced with RuntimeHandler.MonitorCgroup.
        # conmon_cgroup = ""

        # Environment variable list for the conmon process, used for passing necessary
        # environment variables to conmon or the runtime.
        # This option is currently deprecated, and will be replaced with RuntimeHandler.MonitorEnv.
        # conmon_env = [
        # ]

        # Additional environment variables to set for all the
        # containers. These are overridden if set in the
        # container image spec or in the container runtime configuration.
        # default_env = [
        # ]

        # If true, SELinux will be used for pod separation on the host.
        # selinux = false

        # Path to the seccomp.json profile which is used as the default seccomp profile
        # for the runtime. If not specified, then the internal default seccomp profile
        # will be used. This option supports live configuration reload.
        # seccomp_profile = ""

        # Changes the meaning of an empty seccomp profile. By default
        # (and according to CRI spec), an empty profile means unconfined.
        # This option tells CRI-O to treat an empty profile as the default profile,
        # which might increase security.
        # seccomp_use_default_when_empty = true

        # Used to change the name of the default AppArmor profile of CRI-O. The default
        # profile name is "crio-default". This profile only takes effect if the user
        # does not specify a profile via the Kubernetes Pod's metadata annotation. If
        # the profile is set to "unconfined", then this equals to disabling AppArmor.
        # This option supports live configuration reload.
        # apparmor_profile = "crio-default"

        # Path to the blockio class configuration file for configuring
        # the cgroup blockio controller.
        # blockio_config_file = ""

        # Used to change irqbalance service config file path which is used for configuring
        # irqbalance daemon.
        # irqbalance_config_file = "/etc/sysconfig/irqbalance"

        # Path to the RDT configuration file for configuring the resctrl pseudo-filesystem.
        # This option supports live configuration reload.
        # rdt_config_file = ""

        # Cgroup management implementation used for the runtime.
        # cgroup_manager = "systemd"

        # Specify whether the image pull must be performed in a separate cgroup.
        # separate_pull_cgroup = ""

        # List of default capabilities for containers. If it is empty or commented out,
        # only the capabilities defined in the containers json file by the user/kube
        # will be added.
        # default_capabilities = [
        # 	"CHOWN",
        # 	"DAC_OVERRIDE",
        # 	"FSETID",
        # 	"FOWNER",
        # 	"SETGID",
        # 	"SETUID",
        # 	"SETPCAP",
        # 	"NET_BIND_SERVICE",
        # 	"KILL",
        # ]

        # List of default sysctls. If it is empty or commented out, only the sysctls
        # defined in the container json file by the user/kube will be added.
        # default_sysctls = [
        # ]

        # List of devices on the host that a
        # user can specify with the "io.kubernetes.cri-o.Devices" allowed annotation.
        # allowed_devices = [
        # 	"/dev/fuse",
        # ]

        # List of additional devices. specified as
        # "<device-on-host>:<device-on-container>:<permissions>", for example: "--device=/dev/sdc:/dev/xvdc:rwm".
        # If it is empty or commented out, only the devices
        # defined in the container json file by the user/kube will be added.
        # additional_devices = [
        # ]

        # List of directories to scan for CDI Spec files.
        # cdi_spec_dirs = [
        # 	"/etc/cdi",
        # 	"/var/run/cdi",
        # ]

        # Change the default behavior of setting container devices uid/gid from CRI's
        # SecurityContext (RunAsUser/RunAsGroup) instead of taking host's uid/gid.
        # Defaults to false.
        # device_ownership_from_security_context = false

        # Path to OCI hooks directories for automatically executed hooks. If one of the
        # directories does not exist, then CRI-O will automatically skip them.
        # hooks_dir = [
        # 	"/usr/share/containers/oci/hooks.d",
        # ]

        # Path to the file specifying the defaults mounts for each container. The
        # format of the config is /SRC:/DST, one mount per line. Notice that CRI-O reads
        # its default mounts from the following two files:
        #
        #   1) /etc/containers/mounts.conf (i.e., default_mounts_file): This is the
        #      override file, where users can either add in their own default mounts, or
        #      override the default mounts shipped with the package.
        #
        #   2) /usr/share/containers/mounts.conf: This is the default file read for
        #      mounts. If you want CRI-O to read from a different, specific mounts file,
        #      you can change the default_mounts_file. Note, if this is done, CRI-O will
        #      only add mounts it finds in this file.
        #
        # default_mounts_file = ""

        # Maximum number of processes allowed in a container.
        # This option is deprecated. The Kubelet flag '--pod-pids-limit' should be used instead.
        # pids_limit = 0

        # Maximum sized allowed for the container log file. Negative numbers indicate
        # that no size limit is imposed. If it is positive, it must be >= 8192 to
        # match/exceed conmon's read buffer. The file is truncated and re-opened so the
        # limit is never exceeded. This option is deprecated. The Kubelet flag '--container-log-max-size' should be used instead.
        # log_size_max = -1

        # Whether container output should be logged to journald in addition to the kuberentes log file
        # log_to_journald = false

        # Path to directory in which container exit files are written to by conmon.
        # container_exits_dir = "/var/run/crio/exits"

        # Path to directory for container attach sockets.
        # container_attach_socket_dir = "/var/run/crio"

        # The prefix to use for the source of the bind mounts.
        # bind_mount_prefix = ""

        # If set to true, all containers will run in read-only mode.
        # read_only = false

        # Changes the verbosity of the logs based on the level it is set to. Options
        # are fatal, panic, error, warn, info, debug and trace. This option supports
        # live configuration reload.
        # log_level = "info"

        # Filter the log messages by the provided regular expression.
        # This option supports live configuration reload.
        # log_filter = ""

        # The UID mappings for the user namespace of each container. A range is
        # specified in the form containerUID:HostUID:Size. Multiple ranges must be
        # separated by comma.
        # uid_mappings = ""

        # The GID mappings for the user namespace of each container. A range is
        # specified in the form containerGID:HostGID:Size. Multiple ranges must be
        # separated by comma.
        # gid_mappings = ""

        # If set, CRI-O will reject any attempt to map host UIDs below this value
        # into user namespaces.  A negative value indicates that no minimum is set,
        # so specifying mappings will only be allowed for pods that run as UID 0.
        # minimum_mappable_uid = -1

        # If set, CRI-O will reject any attempt to map host GIDs below this value
        # into user namespaces.  A negative value indicates that no minimum is set,
        # so specifying mappings will only be allowed for pods that run as UID 0.
        # minimum_mappable_gid = -1

        # The minimal amount of time in seconds to wait before issuing a timeout
        # regarding the proper termination of the container. The lowest possible
        # value is 30s, whereas lower values are not considered by CRI-O.
        # ctr_stop_timeout = 30

        # drop_infra_ctr determines whether CRI-O drops the infra container
        # when a pod does not have a private PID namespace, and does not use
        # a kernel separating runtime (like kata).
        # It requires manage_ns_lifecycle to be true.
        # drop_infra_ctr = true

        # infra_ctr_cpuset determines what CPUs will be used to run infra containers.
        # You can use linux CPU list format to specify desired CPUs.
        # To get better isolation for guaranteed pods, set this parameter to be equal to kubelet reserved-cpus.
        # infra_ctr_cpuset = ""

        # The directory where the state of the managed namespaces gets tracked.
        # Only used when manage_ns_lifecycle is true.
        # namespaces_dir = "/var/run"

        # pinns_path is the path to find the pinns binary, which is needed to manage namespace lifecycle
        # pinns_path = ""

        # default_runtime is the _name_ of the OCI runtime to be used as the default.
        # The name is matched against the runtimes map below. If this value is changed,
        # the corresponding existing entry from the runtimes map below will be ignored.
        # default_runtime = "runc"

        # A list of paths that, when absent from the host,
        # will cause a container creation to fail (as opposed to the current behavior being created as a directory).
        # This option is to protect from source locations whose existence as a directory could jepordize the health of the node, and whose
        # creation as a file is not desired either.
        # An example is /etc/hostname, which will cause failures on reboot if it's created as a directory, but often doesn't exist because
        # the hostname is being managed dynamically.
        # absent_mount_sources_to_reject = [
        # ]

        # The "crio.runtime.runtimes" table defines a list of OCI compatible runtimes.
        # The runtime to use is picked based on the runtime handler provided by the CRI.
        # If no runtime handler is provided, the runtime will be picked based on the level
        # of trust of the workload. Each entry in the table should follow the format:
        #
        #[crio.runtime.runtimes.runtime-handler]
        #  runtime_path = "/path/to/the/executable"
        #  runtime_type = "oci"
        #  runtime_root = "/path/to/the/root"
        #  privileged_without_host_devices = false
        #  allowed_annotations = []
        # Where:
        # - runtime-handler: name used to identify the runtime
        # - runtime_path (optional, string): absolute path to the runtime executable in
        #   the host filesystem. If omitted, the runtime-handler identifier should match
        #   the runtime executable name, and the runtime executable should be placed
        #   in $PATH.
        # - runtime_type (optional, string): type of runtime, one of: "oci", "vm". If
        #   omitted, an "oci" runtime is assumed.
        # - runtime_root (optional, string): root directory for storage of containers
        #   state.
        # - runtime_config_path (optional, string): the path for the runtime configuration
        #   file. This can only be used with when using the VM runtime_type.
        # - privileged_without_host_devices (optional, bool): an option for restricting
        #   host devices from being passed to privileged containers.
        # - allowed_annotations (optional, array of strings): an option for specifying
        #   a list of experimental annotations that this runtime handler is allowed to process.
        #   The currently recognized values are:
        #   "io.kubernetes.cri-o.userns-mode" for configuring a user namespace for the pod.
        #   "io.kubernetes.cri-o.cgroup2-mount-hierarchy-rw" for mounting cgroups writably when set to "true".
        #   "io.kubernetes.cri-o.Devices" for configuring devices for the pod.
        #   "io.kubernetes.cri-o.ShmSize" for configuring the size of /dev/shm.
        #   "io.kubernetes.cri-o.UnifiedCgroup.$CTR_NAME" for configuring the cgroup v2 unified block for a container.
        #   "io.containers.trace-syscall" for tracing syscalls via the OCI seccomp BPF hook.
        #   "io.kubernetes.cri.rdt-class" for setting the RDT class of a container
        # - monitor_exec_cgroup (optional, string): if set to "container", indicates exec probes
        #   should be moved to the container's cgroup


        # [crio.runtime.runtimes.runc]
        # runtime_path = ""
        # runtime_type = "oci"
        # runtime_root = "/run/runc"
        # runtime_config_path = ""

        # 
        # allowed_annotations = [
        # 	"io.containers.trace-syscall",
        # ]
        # 
        # monitor_path = ""
        # 
        # monitor_env = [
        # 	"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        # ]
        # 
        # monitor_cgroup = "system.slice"
        # monitor_exec_cgroup = ""
        # 

        # crun is a fast and lightweight fully featured OCI runtime and C library for
        # running containers
        #[crio.runtime.runtimes.crun]

        # Kata Containers is an OCI runtime, where containers are run inside lightweight
        # VMs. Kata provides additional isolation towards the host, minimizing the host attack
        # surface and mitigating the consequences of containers breakout.

        # Kata Containers with the default configured VMM
        #[crio.runtime.runtimes.kata-runtime]

        # Kata Containers with the QEMU VMM
        #[crio.runtime.runtimes.kata-qemu]

        # Kata Containers with the Firecracker VMM
        #[crio.runtime.runtimes.kata-fc]

        # The workloads table defines ways to customize containers with different resources
        # that work based on annotations, rather than the CRI.
        # Note, the behavior of this table is EXPERIMENTAL and may change at any time.
        # Each workload, has a name, activation_annotation, annotation_prefix and set of resources it supports mutating.
        # The currently supported resources are "cpu" (to configure the cpu shares) and "cpuset" to configure the cpuset.
        # Each resource can have a default value specified, or be empty.
        # For a container to opt-into this workload, the pod should be configured with the annotation $activation_annotation (key only, value is ignored).
        # To customize per-container, an annotation of the form $annotation_prefix.$resource/$ctrName = "value" can be specified
        # signifying for that resource type to override the default value.
        # If the annotation_prefix is not present, every container in the pod will be given the default values.
        # Example:
        # [crio.runtime.workloads.workload-type]
        # activation_annotation = "io.crio/workload"
        # annotation_prefix = "io.crio.workload-type"
        # [crio.runtime.workloads.workload-type.resources]
        # cpuset = 0
        # cpushares = "0-1"
        # Where:
        # The workload name is workload-type.
        # To specify, the pod must have the "io.crio.workload" annotation (this is a precise string match).
        # This workload supports setting cpuset and cpu resources.
        # annotation_prefix is used to customize the different resources.
        # To configure the cpu shares a container gets in the example above, the pod would have to have the following annotation:
        # "io.crio.workload-type/$container_name = {"cpushares": "value"}"
        # 

        # The crio.image table contains settings pertaining to the management of OCI images.
        #
        # CRI-O reads its configured registries defaults from the system wide
        # containers-registries.conf(5) located in /etc/containers/registries.conf. If
        # you want to modify just CRI-O, you can change the registries configuration in
        # this file. Otherwise, leave insecure_registries and registries commented out to
        # use the system's defaults from /etc/containers/registries.conf.
        [crio.image]

        # Default transport for pulling images from a remote container storage.
        # default_transport = "docker://"

        # The path to a file containing credentials necessary for pulling images from
        # secure registries. The file is similar to that of /var/lib/kubelet/config.json
        # global_auth_file = ""

        # The image used to instantiate infra containers.
        # This option supports live configuration reload.
        # pause_image = "registry.k8s.io/pause:3.6"

        # The path to a file containing credentials specific for pulling the pause_image from
        # above. The file is similar to that of /var/lib/kubelet/config.json
        # This option supports live configuration reload.
        # pause_image_auth_file = ""

        # The command to run to have a container stay in the paused state.
        # When explicitly set to "", it will fallback to the entrypoint and command
        # specified in the pause image. When commented out, it will fallback to the
        # default: "/pause". This option supports live configuration reload.
        # pause_command = "/pause"

        # Path to the file which decides what sort of policy we use when deciding
        # whether or not to trust an image that we've pulled. It is not recommended that
        # this option be used, as the default behavior of using the system-wide default
        # policy (i.e., /etc/containers/policy.json) is most often preferred. Please
        # refer to containers-policy.json(5) for more details.
        # signature_policy = ""

        # List of registries to skip TLS verification for pulling images. Please
        # consider configuring the registries via /etc/containers/registries.conf before
        # changing them here.
        # insecure_registries = [
        # ]

        # Controls how image volumes are handled. The valid values are mkdir, bind and
        # ignore; the latter will ignore volumes entirely.
        # image_volumes = "mkdir"

        # Temporary directory to use for storing big files
        # big_files_temporary_dir = ""

        # The crio.network table containers settings pertaining to the management of
        # CNI plugins.
        [crio.network]

        # The default CNI network name to be selected. If not set or "", then
        # CRI-O will pick-up the first one found in network_dir.
        # cni_default_network = ""

        # Path to the directory where CNI configuration files are located.
        # network_dir = "/etc/cni/net.d/"

        # Paths to directories where CNI plugin binaries are located.
        # plugin_dirs = [
        # 	"/opt/cni/bin/",
        # ]

        # A necessary configuration for Prometheus based metrics retrieval
        [crio.metrics]

        # Globally enable or disable metrics support.
        # enable_metrics = false

        # Specify enabled metrics collectors.
        # Per default all metrics are enabled.
        # It is possible, to prefix the metrics with "container_runtime_" and "crio_".
        # For example, the metrics collector "operations" would be treated in the same
        # way as "crio_operations" and "container_runtime_crio_operations".
        # metrics_collectors = [
        # 	"operations",
        # 	"operations_latency_microseconds_total",
        # 	"operations_latency_microseconds",
        # 	"operations_errors",
        # 	"image_pulls_by_digest",
        # 	"image_pulls_by_name",
        # 	"image_pulls_by_name_skipped",
        # 	"image_pulls_failures",
        # 	"image_pulls_successes",
        # 	"image_pulls_layer_size",
        # 	"image_layer_reuse",
        # 	"containers_oom_total",
        # 	"containers_oom",
        # 	"processes_defunct",
        # 	"operations_total",
        # 	"operations_latency_seconds",
        # 	"operations_latency_seconds_total",
        # 	"operations_errors_total",
        # 	"image_pulls_bytes_total",
        # 	"image_pulls_skipped_bytes_total",
        # 	"image_pulls_failure_total",
        # 	"image_pulls_success_total",
        # 	"image_layer_reuse_total",
        # 	"containers_oom_count_total",
        # ]
        # The port on which the metrics server will listen.
        # metrics_port = 9090

        # Local socket path to bind the metrics server to
        # metrics_socket = ""

        # The certificate for the secure metrics server.
        # If the certificate is not available on disk, then CRI-O will generate a
        # self-signed one. CRI-O also watches for changes of this path and reloads the
        # certificate on any modification event.
        # metrics_cert = ""

        # The certificate key for the secure metrics server.
        # Behaves in the same way as the metrics_cert.
        # metrics_key = ""

        # A necessary configuration for OpenTelemetry trace data exporting
        [crio.tracing]

        # Globally enable or disable exporting OpenTelemetry traces.
        # enable_tracing = false

        # Address on which the gRPC trace collector listens on.
        # tracing_endpoint = "0.0.0.0:4317"

        # Number of samples to collect per million spans.
        # tracing_sampling_rate_per_million = 0

        # Necessary information pertaining to container and pod stats reporting.
        [crio.stats]

        # The number of seconds between collecting pod and container stats.
        # If set to 0, the stats are collected on-demand instead.
        # stats_collection_period = 0
    post_install: |
      echo "Building manpages"
      go-md2man -in "${target}/share/man/man8/crio.8.md"        -out "${target}/share/man/man8/crio.8"
      go-md2man -in "${target}/share/man/man8/crio-status.8.md" -out "${target}/share/man/man8/crio-status.8"
      go-md2man -in "${target}/share/man/man5/crio.conf.5.md"   -out "${target}/share/man/man5/crio.conf.5"
      go-md2man -in "${target}/share/man/man5/crio.conf.d.5.md" -out "${target}/share/man/man5/crio.conf.d.5"
      rm \
          "${target}/share/man/man8/crio.8.md" \      
          "${target}/share/man/man8/crio-status.8.md" \
          "${target}/share/man/man5/crio.conf.5.md" \
          "${target}/share/man/man5/crio.conf.d.5.md"
      echo "Install systemd unit"
      sed -i "s|ExecStart=/usr/local/bin/crio|ExecStart=${relative_target}/bin/crio|" "${prefix}/etc/systemd/system/crio.service"
      sed -i "s|ExecStart=/usr/local/bin/crio|ExecStart=${relative_target}/bin/crio|" "${prefix}/etc/systemd/system/crio-wipe.service"
      if test -z "${prefix}"; then
          if has_systemd; then
              echo "Reload systemd"
              systemctl daemon-reload
          fi
      fi

  - name: crictl
    version: 1.24.2
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    tags:
    - k8s
    - kubernetes
    - runtime
    - cri
    download:
    - url: https://github.com/kubernetes-sigs/cri-tools/releases/download/v${version}/crictl-v${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
    files:
    - path: ${prefix}/etc/crictl.yaml
      content: |
        # Possible values for runtime-endpoint and image-endpoint
        # dockershim: unix:///var/run/dockershim.sock
        # containerd: unix:///run/containerd/containerd.sock
        # crio: unix:///run/crio/crio.sock
        # cri-dockerd: unix:///var/run/cri-dockerd.sock
        #runtime-endpoint: YOUR-CHOICE
        #image-endpoint: YOUR-CHOICE
        timeout: 2
        debug: false
        pull-image-on-create: false

  - name: crun
    version: 1.5
    check: ${binary} --version | grep "crun version" | cut -d' ' -f3
    needs:
    - docker
    tags:
    - runtime
    - redhat
    - oci
    download:
    - url:
        x86_64: https://github.com/nicholasdille/crun-static/releases/download/v${version}/crun-${alt_arch}.tar.gz
      type: tarball
      path: ${target}
    files:
    - path: ${prefix}/etc/containerd/conf.d/crun.toml
      content: |
        version = 2
        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.crun]
          runtime_type = "io.containerd.runc.v2"
        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.crun.options]
          BinaryName = "/usr/local/bin/crun"
    post_install: |
      if ! test -f "${prefix}/etc/docker/daemon.json" || ! test "$(jq --raw-output '.runtimes | keys | any(. == "crun")' "${prefix}/etc/docker/daemon.json")" == "true"; then
          echo "Add runtime to Docker"
          # shellcheck disable=SC2094
          cat >"${docker_setup_cache}/daemon.json-crun.sh" <<EOF
      cat <<< "\$(jq --arg target "${target}" '. * {"runtimes":{"crun":{"path":"\(\$target)/bin/crun"}}}' "${prefix}/etc/docker/daemon.json")" >"${prefix}/etc/docker/daemon.json"
      EOF
          touch "${docker_setup_cache}/docker_restart"
      fi

  - name: ctop
    version: 0.7.7
    check: ${binary} -v | cut -d, -f1 | cut -d' ' -f3
    tags:
    - analysis
    - management
    - tui
    needs:
    - docker
    download:
    - url: https://github.com/bcicen/ctop/releases/download/v${version}/ctop-${version}-linux-${alt_arch}
      type: executable

  - name: cyclonedx-cli
    version: 0.24.0
    tags:
    - security
    - sbom
    download:
    - url:
        x86_64: https://github.com/CycloneDX/cyclonedx-cli/releases/download/v${version}/cyclonedx-linux-x64
        aarch64: https://github.com/CycloneDX/cyclonedx-cli/releases/download/v${version}/cyclonedx-linux-arm64
      type: executable

  - name: dagger
    version: 0.2.28
    check: ${binary} version | cut -d' ' -f2
    tags:
    - management
    download:
    - url: https://github.com/dagger/dagger/releases/download/v${version}/dagger_v${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - dagger

  - name: dasel
    version: 1.26.0
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    tags:
    - conversion
    - format
    download:
    - url: https://github.com/TomWright/dasel/releases/download/v${version}/dasel_linux_${alt_arch}
      type: executable

  - name: dive
    version: 0.10.0
    check: ${binary} --version | cut -d' ' -f2
    needs:
    - docker
    tags:
    - analysis
    - build
    - tui
    download:
    - url: https://github.com/wagoodman/dive/releases/download/v${version}/dive_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - dive

  - name: docker
    version: 20.10.17
    binary: dockerd
    check: ${binary} --version | cut -d, -f1 | cut -d' ' -f3
    needs:
    - iptables
    - fuse-overlayfs
    - docker-manpages
    tags:
    - default
    - docker
    - runtime
    - build
    - oci
    download:
    - url: https://download.docker.com/linux/static/stable/${arch}/docker-${version}.tgz
      type: tarball
      strip: 1
      path: ${target}/libexec/docker/bin
    - url: https://download.docker.com/linux/static/stable/${arch}/docker-rootless-extras-${version}.tgz
      type: tarball
      strip: 1
      path: ${target}/libexec/docker/bin
    - url: https://github.com/docker/cli/raw/v${version}/contrib/completion/bash/docker
      type: file
      path: ${target}/share/bash-completion/completions/docker
    - url: https://github.com/docker/cli/raw/v${version}/contrib/completion/fish/docker.fish
      type: file
      path: ${target}/share/fish/vendor_completions.d/docker.fish
    - url: https://github.com/docker/cli/raw/v${version}/contrib/completion/zsh/_docker
      type: file
      path: ${target}/share/zsh/vendor-completions/_docker
    - url: https://github.com/moby/moby/raw/v${version}/contrib/init/systemd/docker.service
      type: file
      path: ${prefix}/etc/systemd/system/docker.service
    - url: https://github.com/moby/moby/raw/v${version}/contrib/init/systemd/docker.socket
      type: file
      path: ${prefix}/etc/systemd/system/docker.socket
    - url: https://github.com/moby/moby/raw/v${version}/contrib/init/sysvinit-debian/docker.default
      type: file
      path: contrib/${tool}/sysvinit/debian/docker.default
    - url: https://github.com/moby/moby/raw/v${version}/contrib/init/sysvinit-debian/docker
      type: file
      path: contrib/${tool}/sysvinit/debian/docker
    - url: https://github.com/moby/moby/raw/v${version}/contrib/init/sysvinit-redhat/docker.sysconfig
      type: file
      path: contrib/${tool}/sysvinit/redhat/docker.sysconfig
    - url: https://github.com/moby/moby/raw/v${version}/contrib/init/sysvinit-redhat/docker
      type: file
      path: contrib/${tool}/sysvinit/redhat/docker
    - url: https://github.com/moby/moby/raw/v${version}/contrib/init/openrc/docker.confd
      type: file
      path: contrib/${tool}/openrc/docker.confd
    - url: https://github.com/moby/moby/raw/v${version}/contrib/init/openrc/docker.initd
      type: file
      path: contrib/${tool}/openrc/docker.initd
    post_install: |
      echo "Move binaries (@ ${SECONDS} seconds)"
      mv "${target}/libexec/docker/bin/dockerd" "${target}/bin"
      mv "${target}/libexec/docker/bin/docker" "${target}/bin"
      mv "${target}/libexec/docker/bin/docker-proxy" "${target}/bin"
      echo "Move rootless scripts (@ ${SECONDS} seconds)"
      mv "${target}/libexec/docker/bin/dockerd-rootless.sh" "${target}/bin"
      mv "${target}/libexec/docker/bin/dockerd-rootless-setuptool.sh" "${target}/bin"
      echo "Binaries installed after ${SECONDS} seconds."

      echo "Patch paths in systemd unit files (@ ${SECONDS} seconds)"
      sed -i "/^\[Service\]/a Environment=PATH=${relative_target}/libexec/docker/bin:/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/sbin:/usr/local/bin" "${prefix}/etc/systemd/system/docker.service"
      sed -i -E "s|/usr/bin/dockerd|${relative_target}/bin/dockerd|" "${prefix}/etc/systemd/system/docker.service"

      echo "Patch paths in init scripts (@ ${SECONDS} seconds)"
      sed -i -E "s|^(export PATH=)|\1${relative_target}/libexec/docker/bin:|" "${docker_setup_contrib}/${tool}/sysvinit/debian/docker"
      sed -i -E "s|^DOCKERD=/usr/bin/dockerd|DOCKERD=${relative_target}/bin/dockerd|" "${docker_setup_contrib}/${tool}/sysvinit/debian/docker"
      chmod +x "${docker_setup_contrib}/${tool}/sysvinit/debian/docker"
      sed -i -E "s|(^prog=)|export PATH="${relative_target}/libexec/docker/bin:${relative_target}/sbin:${relative_target}/bin:\${PATH}"\n\n\1|" "${docker_setup_contrib}/${tool}/sysvinit/redhat/docker"
      sed -i -E "s|/usr/bin/dockerd|${relative_target}/bin/dockerd|" "${docker_setup_contrib}/${tool}/sysvinit/redhat/docker"
      chmod +x "${docker_setup_contrib}/${tool}/sysvinit/redhat/docker"
      sed -i -E "s|^(command=)|export PATH="${relative_target}/libexec/docker/bin:\${PATH}"\n\n\1|" "${docker_setup_contrib}/${tool}/openrc/docker.initd"
      sed -i "s|/usr/bin/dockerd|${relative_target}/bin/dockerd|" "${docker_setup_contrib}/${tool}/openrc/docker.initd"
      sed -i "s|/usr/bin/dockerd|${relative_target}/bin/dockerd|" "${docker_setup_contrib}/${tool}/openrc/docker.confd"
      chmod +x "${docker_setup_contrib}/${tool}/openrc/docker.initd"

      if test -f "${prefix}/etc/group"; then
          echo "Create group (@ ${SECONDS} seconds)"
          groupadd --prefix "${prefix}" --system --force docker
      fi

      echo "Configure daemon (@ ${SECONDS} seconds)"
      mkdir -p "${prefix}/etc/docker"
      if ! test -f "${prefix}/etc/docker/daemon.json"; then
          echo "Initialize dockerd configuration"
          echo "{}" >"${prefix}/etc/docker/daemon.json"
      fi

      if test -f "${prefix}/etc/fstab"; then
          root_fs="$(cat "${prefix}/etc/fstab" | tr -s ' ' | grep " / " | cut -d' ' -f3)"
          if test -z "${root_fs}"; then
              root_fs="$(mount | grep " on / " | cut -d' ' -f5)"
          fi
          echo "Found ${root_fs} on /"

          if test "${root_fs}" == "overlay"; then

              if has_tool "fuse-overlayfs" || tool_will_be_installed "fuse-overlayfs"; then
                  info "Waiting for fuse-overlayfs to be installed"
                  wait_for_tool "fuse-overlayfs"

                  echo "Configuring storage driver for DinD"
                  # shellcheck disable=SC2094
                  cat <<< "$(jq '. * {"storage-driver": "fuse-overlayfs"}' "${prefix}/etc/docker/daemon.json")" >"${prefix}/etc/docker/daemon.json"

              else
                  warning "fuse-overlayfs should be planned for installation."
              fi
              touch "${docker_setup_cache}/docker_restart"
          fi
      fi

      if ! test "$(jq '."exec-opts" // [] | any(. | startswith("native.cgroupdriver="))' "${prefix}/etc/docker/daemon.json")" == "true"; then
          echo "Configuring native cgroup driver"
          # shellcheck disable=SC2094
          cat <<< "$(jq '."exec-opts" += ["native.cgroupdriver=cgroupfs"]' "${prefix}/etc/docker/daemon.json")" >"${prefix}/etc/docker/daemon.json"
          touch "${docker_setup_cache}/docker_restart"
      fi
      if ! test "$(jq '. | keys | any(. == "default-runtime")' "${prefix}/etc/docker/daemon.json")" == true; then
          echo "Set default runtime"
          # shellcheck disable=SC2094
          cat <<< "$(jq '. * {"default-runtime": "runc"}' "${prefix}/etc/docker/daemon.json")" >"${prefix}/etc/docker/daemon.json"
          touch "${docker_setup_cache}/docker_restart"
      fi
      # shellcheck disable=SC2016
      if test -n "${docker_address_base}" && test -n "${docker_address_size}" && ! test "$(jq --arg base "${docker_address_base}" --arg size "${docker_address_size}" '."default-address-pool" | any(.base == $base and .size == $size)' "${prefix}/etc/docker/daemon.json")" == "true"; then
          echo "Add address pool with base ${docker_address_base} and size ${docker_address_size}"
          # shellcheck disable=SC2094
          cat <<< "$(jq --args base "${docker_address_base}" --arg size "${docker_address_size}" '."default-address-pool" += {"base": $base, "size": $size}' "${prefix}/etc/docker/daemon.json")" >"${prefix}/etc/docker/daemon.json"
          touch "${docker_setup_cache}/docker_restart"
      fi
      # shellcheck disable=SC2016
      if test -n "${docker_registry_mirror}" && ! test "$(jq --arg mirror "${docker_registry_mirror}" '."registry-mirrors" // [] | any(. == $mirror)' "${prefix}/etc/docker/daemon.json")" == "true"; then
          echo "Add registry mirror ${docker_registry_mirror}"
          # shellcheck disable=SC2094
          # shellcheck disable=SC2016
          cat <<< "$(jq --args mirror "${docker_registry_mirror}" '."registry-mirrors" += ["\($mirror)"]' "${prefix}/etc/docker/daemon.json")" >"${prefix}/etc/docker/daemon.json"
          touch "${docker_setup_cache}/docker_restart"
      fi
      if ! test "$(jq --raw-output '.features.buildkit // false' "${prefix}/etc/docker/daemon.json")" == true; then
          echo "Enable BuildKit"
          # shellcheck disable=SC2094
          cat <<< "$(jq '. * {"features":{"buildkit":true}}' "${prefix}/etc/docker/daemon.json")" >"${prefix}/etc/docker/daemon.json"
          touch "${docker_setup_cache}/docker_restart"
      fi
      echo "Check if daemon.json is valid JSON (@ ${SECONDS} seconds)"
      if ! jq --exit-status '.' "${prefix}/etc/docker/daemon.json" >/dev/null 2>&1; then
          error "${prefix}/etc/docker/daemon.json is not valid JSON."
          exit 1
      fi

      if docker_is_running; then
          touch "${docker_setup_cache}/docker_already_present"
          echo "Found that Docker is already present after ${SECONDS} seconds."
          warning "Docker is already running. Skipping init script and daemon configuration."

      else
          if is_debian || is_clearlinux; then
              echo "Install init script for debian"
              mkdir -p "${prefix}/etc/default" "${prefix}/etc/init.d"
              cp "${docker_setup_contrib}/${tool}/sysvinit/debian/docker.default" "${prefix}/etc/default/docker"
              cp "${docker_setup_contrib}/${tool}/sysvinit/debian/docker" "${prefix}/etc/init.d/docker"
              
          elif is_redhat; then
              echo "Install init script for redhat"
              mkdir -p "${prefix}/etc/sysconfig" "${prefix}/etc/init.d"
              cp "${docker_setup_contrib}/${tool}/sysvinit/redhat/docker.sysconfig" "${prefix}/etc/sysconfig/docker"
              cp "${docker_setup_contrib}/${tool}/sysvinit/redhat/docker" "${prefix}/etc/init.d/docker"
              
          elif is_alpine; then
              echo "Install openrc script for alpine"
              mkdir -p "${prefix}/etc/conf.d" "${prefix}/etc/init.d"
              cp "${docker_setup_contrib}/${tool}/openrc/docker.confd" "${prefix}/etc/conf.d/docker"
              cp "${docker_setup_contrib}/${tool}/openrc/docker.initd" "${prefix}/etc/init.d/docker"
              openrc
          else
              warning "Unable to install init script because the distributon is unknown."
          fi

          if test -z "${prefix}"; then
              if has_systemd; then
                  echo "Reload systemd (@ ${SECONDS} seconds)"
                  systemctl daemon-reload
                  if ! systemctl is-active --quiet docker; then
                      echo "Start dockerd (@ ${SECONDS} seconds)"
                      systemctl enable docker
                      systemctl start docker
                      touch "${docker_setup_cache}/docker_restart_allowed"
                  fi
              else
                  if ! docker_is_running; then
                      echo "Start dockerd (@ ${SECONDS} seconds)"
                      "${prefix}/etc/init.d/docker" start
                      touch "${docker_setup_cache}/docker_restart_allowed"
                  fi
                  warning "Init script was installed but you must enable Docker yourself."
              fi
          fi
          echo "Wait for Docker daemon to start (@ ${SECONDS} seconds)"

          wait_for_docker
          if ! docker_is_running; then
              error "Failed to start Docker."
              exit 1
          fi
          echo "Finished starting Docker after ${SECONDS} seconds."
      fi
      echo "Finished after ${SECONDS} seconds."

  - name: docker-manpages
    version: 20.10.17
    binary: false
    tags:
    - default
    - docker
    - runtime
    - build
    - oci
    download:
    - url: https://github.com/nicholasdille/docker-cli-manpages/releases/download/v${version}/docker-cli-manpages.tar.gz
      type: tarball
      path: ${target}

  - name: docker-compose-v1
    version: 1.29.2
    check: ${binary} version --short
    flags:
    - docker-compose-v1
    tags:
    - default
    - docker
    - compose
    download:
    - url:
        x86_64: https://github.com/docker/compose/releases/download/${version}/docker-compose-Linux-x86_64
      type: executable
    files:
    - path: ${target}/bin/docker-compose
      content: |
        #!/bin/bash

        docker_cli_plugin_metadata() {
          if [ -z "$DOCKER_COMPOSE_VERSION" ]; then
            export DOCKER_COMPOSE_VERSION
                DOCKER_COMPOSE_VERSION="$(docker-compose --version | cut -d " " -f 3 | cut -d "," -f 1)"
          fi

          local vendor="Docker"
          local url="https://www.docker.com"
          local description="Define and run multi-container applications"
          cat <<-EOF
          {"SchemaVersion":"0.1.0","Vendor":"${vendor}","Version":"${DOCKER_COMPOSE_VERSION}","ShortDescription":"${description}","URL":"${url}"}
        EOF
        }

        case "$1" in
          docker-cli-plugin-metadata)
            docker_cli_plugin_metadata
            ;;
          *)
            shift
            exec docker-compose "$@"
            ;;
        esac

  - name: docker-compose-switch
    version: 1.0.5
    binary: docker-compose
    flags:
    - not-docker-compose-v1
    tags:
    - default
    download:
    - url: https://github.com/docker/compose-switch/releases/download/v${version}/docker-compose-linux-${alt_arch}
      type: executable

  - name: docker-compose
    version: 2.9.0
    binary: ${target}/libexec/docker/cli-plugins/docker-compose
    check: ${binary} compose version --short
    needs:
    - docker
    - docker-compose-switch
    flags:
    - not-docker-compose-v1
    tags:
    - default
    - docker
    - compose
    - plugin
    download:
    - url: https://github.com/docker/compose/releases/download/v${version}/docker-compose-linux-${arch}
      type: executable

  - name: docker-credential-acr-env
    version: 0.7.0
    needs:
    - docker
    tags:
    - docker
    - security
    download:
    - url: https://github.com/chrismellard/docker-credential-acr-env/releases/download/${version}/docker-credential-acr-env_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - docker-credential-acr-env

  - name: docker-credential-ecr-login
    version: 0.6.0
    needs:
    - docker
    tags:
    - docker
    - security
    download:
    - url: https://amazon-ecr-credential-helper-releases.s3.us-east-2.amazonaws.com/${version}/linux-${alt_arch}/docker-credential-ecr-login
      type: executable

  - name: docker-credential-gcr
    version: 2.1.5
    needs:
    - docker
    tags:
    - docker
    - security
    download:
    - url: https://github.com/GoogleCloudPlatform/docker-credential-gcr/releases/download/v${version}/docker-credential-gcr_linux_${alt_arch}-${version}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - docker-credential-gcr

  - name: docker-credential-helpers
    version: 0.6.4
    binary: docker-credential-pass
    needs:
    - docker
    tags:
    - docker
    - security
    download:
    - url:
        x86_64: https://github.com/docker/docker-credential-helpers/releases/download/v${version}/docker-credential-pass-v${version}-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
    - url:
        x86_64: https://github.com/docker/docker-credential-helpers/releases/download/v${version}/docker-credential-secretservice-v${version}-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin

  - name: docker-credential-magic
    version: 0.8.1
    needs:
    - docker
    tags:
    - docker
    - security
    download:
    - url:
        x86_64: https://github.com/docker-credential-magic/docker-credential-magic/releases/download/v${version}/docker-credential-magic_Linux_${arch}.tar.gz
        aarch64: https://github.com/docker-credential-magic/docker-credential-magic/releases/download/v${version}/docker-credential-magic_Linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - docker-credential-magic
      - docker-credential-magician

  - name: docker-machine
    version: 0.16.2
    check: ${binary} --version | cut -d, -f1 | cut -d' ' -f3
    tags:
    - docker
    download:
    - url: https://github.com/docker/machine/releases/download/v${version}/docker-machine-Linux-${arch}
      type: executable

  - name: docker-sbom
    version: 0.6.1
    binary: ${target}/libexec/docker/cli-plugins/docker-sbom
    needs:
    - docker
    tags:
    - docker
    - security
    - sbom
    download:
    - url: https://github.com/docker/sbom-cli-plugin/releases/download/v${version}/sbom-cli-plugin_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/libexec/docker/cli-plugins
      files:
      - docker-sbom

  - name: docker-scan
    version: 0.17.0
    binary: ${target}/libexec/docker/cli-plugins/docker-scan
    needs:
    - docker
    tags:
    - docker
    - security
    - plugin
    download:
    - url: https://github.com/docker/scan-cli-plugin/releases/download/v${version}/docker-scan_linux_${alt_arch}
      type: executable

  - name: docuum
    version: 0.21.1
    check: ${binary} --version | cut -d' ' -f2
    needs:
    - docker
    tags:
    - docker
    - management
    dockerfile: |
      FROM rust:${rust_version}
    install: |
      docker_run \
          --workdir /go/src/github.com/stepchowfun/docuum \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/stepchowfun/docuum .
      export RUSTFLAGS='-C target-feature=+crt-static'
      cargo build --release --target x86_64-unknown-linux-gnu
      cp target/x86_64-unknown-linux-gnu/release/docuum /target/bin/
      EOF

  - name: dry
    version: 0.11.1
    check: ${binary} --version | cut -d, -f1 | cut -d' ' -f3
    needs:
    - docker
    tags:
    - analysis
    - management
    - tui
    download:
    - url: https://github.com/moncho/dry/releases/download/v${version}/dry-linux-${alt_arch}
      type: executable

  - name: duffle
    version: 0.3.5-beta.1
    check: ${binary} version
    tags:
    - cnab
    download:
    - url: https://github.com/cnabio/duffle/releases/download/${version}/duffle-linux-${alt_arch}
      type: executable

  - name: dyff
    version: 1.5.4
    check: ${binary} version | cut -d' ' -f3
    tags:
    - development
    - dev
    download:
    - url: https://github.com/homeport/dyff/releases/download/v${version}/dyff_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - dyff
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: faas-cli
    version: 0.14.2
    check: ${binary} version | grep "version:" | cut -d' ' -f3
    tags:
    - serverless
    - faas
    download:
    - url:
        x86_64: https://github.com/openfaas/faas-cli/releases/download/${version}/faas-cli
        aarch64: https://github.com/openfaas/faas-cli/releases/download/${version}/faas-cli-${alt_arch}
      type: executable

  - name: faasd
    version: 0.16.2
    check: ${binary} version | grep faasd | tr '\t' ' ' | cut -d' ' -f3
    needs:
    - containerd
    - faas-cli
    tags:
    - serverless
    - faas
    download:
    - url:
        x86_64: https://github.com/openfaas/faasd/releases/download/${version}/faasd
        aarch64: https://github.com/openfaas/faasd/releases/download/${version}/faasd-${alt_arch}
      type: executable

  - name: firecracker
    version: 1.1.1
    check: ${binary} --version | grep "^Firecracker" | cut -d' ' -f2 | tr -d v
    tags:
    - kvm
    - vm
    - emulation
    download:
    - url: https://github.com/firecracker-microvm/firecracker/releases/download/v${version}/firecracker-v${version}-${arch}.tgz
      type: tarball
      path: ${target}/bin
      strip: 1
      files:
      - release-v${version}-${arch}/firecracker-v${version}-${arch}
      - release-v${version}-${arch}/jailer-v${version}-${arch}
      - release-v${version}-${arch}/seccompiler-bin-v${version}-${arch}
    post_install: |
      mv "${target}/bin/firecracker-v${version}-${arch}"     "${target}/bin/firecracker"
      mv "${target}/bin/jailer-v${version}-${arch}"          "${target}/bin/jailer"
      mv "${target}/bin/seccompiler-bin-v${version}-${arch}" "${target}/bin/seccompiler-bin"

  - name: firectl
    version: 0.1.0
    check: ${binary} --version
    needs:
    - firecracker
    tags:
    - kvm
    - management
    - vm
    - emulation
    download:
    - url:
        x86_64: https://firectl-release.s3.amazonaws.com/firectl-v${version}
      type: executable

  - name: footloose
    version: 0.6.3
    check: ${binary} version | cut -d' ' -f2
    tags:
    - vm
    - emulation
    download:
    - url: https://github.com/weaveworks/footloose/releases/download/${version}/footloose-${version}-linux-${arch}
      type: executable

  - name: fuse-overlayfs
    version: 1.9
    check: ${binary} --version | head -n 1 | cut -d' ' -f3
    tags:
    - default
    - docker
    - storage
    - containerd
    download:
    - url: https://github.com/containers/fuse-overlayfs/releases/download/v${version}/fuse-overlayfs-${arch}
      type: executable

  - name: fuse-overlayfs-snapshotter
    version: 1.0.4
    binary: containerd-fuse-overlayfs-grpc
    needs:
    - fuse-overlayfs
    - containerd
    tags:
    - storage
    - containerd
    download:
    - url: https://github.com/containerd/fuse-overlayfs-snapshotter/releases/download/v${version}/containerd-fuse-overlayfs-${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
    files:
    - path: ${prefix}/etc/systemd/system/fuse-overlayfs-snapshotter.service
      content: |
        [Unit]
        Description=containerd-fuse-overlayfs
        PartOf=containerd

        [Service]
        ExecStart=/usr/local/bin/containerd-fuse-overlayfs-grpc "/var/run/containerd-fuse-overlayfs.sock" "/var/lib/containerd-fuse-overlayfs"
        ExecReload=/bin/kill -s HUP \$MAINPID
        RestartSec=2
        Restart=always
        Type=simple
        KillMode=mixed

        [Install]
        WantedBy=default.target
    - path: ${prefix}/etc/containerd/conf.d/fuse-overlayfs-snapshotter.toml
      content: |
        [proxy_plugins]
          [proxy_plugins."fuse-overlayfs"]
            type = "snapshot"
            address = "/run/containerd-fuse-overlayfs.sock"
    post_install: |
      echo "Install systemd units"
      sed -i "s|ExecStart=/usr/local/bin/containerd-fuse-overlayfs-grpc|ExecStart=${relative_target}/bin/containerd-fuse-overlayfs-grpc|" "${prefix}/etc/systemd/system/fuse-overlayfs-snapshotter.service"
      if test -z "${prefix}"; then
          if has_systemd; then
              echo "Reload systemd"
              systemctl daemon-reload
          fi
      fi

  - name: gh
    version: 2.14.3
    check: ${binary} --version | head -n 1 | cut -d' ' -f3
    tags:
    - development
    download:
    - url: https://github.com/cli/cli/releases/download/v${version}/gh_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}
      strip: 1
    post_install: |
      rm ${target}/LICENSE
      echo "Install completion"
      ${binary} completion -s bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion -s fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion -s zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: gitlab-runner
    version: 15.2.1
    check: ${binary} --version | grep ^Version | tr -s ' ' | cut -d' ' -f2
    tags:
    - development
    - testing
    - automation
    download:
    - url:
        x86_64: https://gitlab.com/gitlab-org/gitlab-runner/-/releases/v${version}/downloads/binaries/gitlab-runner-linux-${alt_arch}
      type: executable
      path: ${target}/bin/gitlab-runner

  - name: gitsign
    version: 0.2.0
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    tags:
    - development
    - security
    download:
    - url: https://github.com/sigstore/gitsign/releases/download/v${version}/gitsign_${version}_linux_${alt_arch}
      type: executable
      path: ${target}/bin/gitsign
    - url: https://github.com/sigstore/gitsign/releases/download/v${version}/gitsign_${version}_windows_${alt_arch}.exe
      type: executable
      path: ${target}/bin/gitsign.exe
    - url: https://github.com/sigstore/gitsign/releases/download/v${version}/gitsign-credential-cache_${version}_linux_${alt_arch}
      type: executable
      path: ${target}/bin/gitsign-credential-cache
    files:
    - path: ${target}/bin/gitsign.sh
      content: |
        #!/bin/bash
        set -o errexit

        BIN=${target}/bin
        GITSIGN=gitsign
        if test -n "${WSL_DISTRO_NAME}"; then
            GITSIGN=gitsign.exe
        fi

        if test -z "$(pidof gitsign-credential-cache)"; then
            gitsign-credential-cache >/dev/null 2>&1 &
        fi
        export GITSIGN_CREDENTIAL_CACHE="${HOME}/.cache/.sigstore/gitsign/cache.sock"

        export GITSIGN_LOG="${HOME}/tmp/gitsign.log"

        exec "${BIN}/${GITSIGN}" "$@"
    post_install: |
      chmod +x "${target}/bin/gitsign.sh"

  - name: glab
    version: 1.22.0
    check: ${binary} version | cut -d' ' -f3
    tags:
    - development
    download:
    - url:
        x86_64: https://github.com/profclems/glab/releases/download/v${version}/glab_${version}_Linux_${arch}.tar.gz
        aarch64: https://github.com/profclems/glab/releases/download/v${version}/glab_${version}_Linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      strip: 1
      files:
      - bin/glab
    post_install: |
      echo "Install completion"
      ${binary} completion -s bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion -s fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion -s zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: glow
    version: 1.4.1
    check: ${binary} --version | cut -d' ' -f3
    tags:
    - markdown
    download:
    - url: https://github.com/charmbracelet/glow/releases/download/v${version}/glow_${version}_linux_${arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - glow

  - name: go-md2man
    version: 2.0.2
    tags:
    - markdown
    download:
    - url: https://github.com/nicholasdille/go-md2man-static/releases/download/v${version}/go-md2man-${alt_arch}.tar.gz
      type: tarball
      path: ${target}

  - name: grype
    version: 0.45.0
    check: ${binary} version | grep "^Version:" | tr -s ' ' | cut -d' ' -f2
    tags:
    - security
    - sbom
    download:
    - url: https://github.com/anchore/grype/releases/download/v${version}/grype_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - grype
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: gvisor
    version: 20220713
    binary: ${target}/bin/runsc
    check: ${binary} --version | grep "runsc version" | cut -d' ' -f3
    needs:
    - docker
    tags:
    - runtime
    - security
    download:
    - url: https://storage.googleapis.com/gvisor/releases/release/${version}/${arch}/runsc
      type: executable
    - url: https://storage.googleapis.com/gvisor/releases/release/${version}/${arch}/containerd-shim-runsc-v1
      type: executable
      path: ${target}/bin/containerd-shim-runsc-v1
    files:
    - path: ${prefix}/etc/containerd/conf.d/gvisor.toml
      content: |
        version = 2
        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
          runtime_type = "io.containerd.runc.v2"
        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runsc]
          runtime_type = "io.containerd.runsc.v1"
    post_install: |
      if ! test -f "${prefix}/etc/docker/daemon.json" || ! test "$(jq --raw-output '.runtimes | keys | any(. == "runsc")' "${prefix}/etc/docker/daemon.json")" == "true"; then
          echo "Add runtime to Docker"
          # shellcheck disable=SC2094
          cat >"${docker_setup_cache}/daemon.json-gvisor.sh" <<EOF
      cat <<< "\$(jq --arg target "${target}" '. * {"runtimes":{"runsc":{"path":"\(\$target)/bin/runsc"}}}' "${prefix}/etc/docker/daemon.json")" >"${prefix}/etc/docker/daemon.json"
      EOF
          touch "${docker_setup_cache}/docker_restart"
      fi

  - name: hadolint
    version: 2.10.0
    check: ${binary} --version | cut -d' ' -f4 | cut -d- -f1
    tags:
    - docker
    - build
    - analysis
    download:
    - url:
        x86_64: https://github.com/hadolint/hadolint/releases/download/v${version}/hadolint-Linux-${arch}
      type: executable

  - name: hcloud
    version: 1.30.1
    check: ${binary} version | cut -d' ' -f2
    tags:
    - cloud
    - management
    download:
    - url: https://github.com/hetznercloud/cli/releases/download/v${version}/hcloud-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - hcloud

  - name: helm
    version: 3.9.2
    check: ${binary} version --short | cut -d+ -f1 | tr -d v
    tags:
    - k8s
    - kubernetes
    - templating
    - package
    - manager
    download:
    - url: https://get.helm.sh/helm-v${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      strip: 1
      files:
      - linux-amd64/helm
    post_install: |
      "${binary}" completion bash >"${target}/share/bash-completion/completions/${name}"
      "${binary}" completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      "${binary}" completion zsh >"${target}/share/zsh/vendor-completions/_${name}"
      if test -z "${prefix}"; then
          echo "Install plugins"
          plugins=(
              https://github.com/mstrzele/helm-edit
              https://github.com/databus23/helm-diff
              https://github.com/aslafy-z/helm-git
              https://github.com/sstarcher/helm-release
              https://github.com/maorfr/helm-backup
              https://github.com/technosophos/helm-keybase
              https://github.com/technosophos/helm-gpg
              https://github.com/cloudogu/helm-sudo
              https://github.com/bloodorangeio/helm-oci-mirror
              https://github.com/UniKnow/helm-outdated
              https://github.com/rimusz/helm-chartify
              https://github.com/random-dwi/helm-doc
              https://github.com/sapcc/helm-outdated-dependencies
              https://github.com/jkroepke/helm-secrets
              https://github.com/sigstore/helm-sigstore
              https://github.com/quintush/helm-unittest
          )
          for url in "${plugins[@]}"; do
              directory="$(basename "${url}")"
              if test -d "${HOME}/.local/share/helm/plugins/${directory}"; then
                  name="${directory//helm-/}"
                  helm plugin update "${name}"
              else
                  helm plugin install "${url}"
              fi
          done
      fi

  - name: helmfile
    version: 0.144.0
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    tags:
    - k8s
    - kubernetes
    - templating
    download:
    - url: https://github.com/roboll/helmfile/releases/download/v${version}/helmfile_linux_${alt_arch}
      type: executable
    - url: https://github.com/roboll/helmfile/raw/v${version}/autocomplete/helmfile_bash_autocomplete
      type: file
      path: ${target}/share/bash-completion/completions/helmfile
    - url: https://github.com/roboll/helmfile/raw/v${version}/autocomplete/helmfile_zsh_autocomplete
      type: file
      path: ${target}/share/zsh/vendor-completions/_helmfile

  - name: hub
    version: 2.14.2
    check: ${binary} --version | grep ^hub | cut -d' ' -f3
    tags:
    - development
    download:
    - url: https://github.com/github/hub/releases/download/v${version}/hub-linux-${alt_arch}-${version}.tgz
      type: tarball
      path: ${target}
      strip: 1
    post_install: |
      rm ${target}/LICENSE ${target}/install ${target}/README.md ${prefix}/etc/README.md
      mv ${prefix}/etc/hub.bash_completion.sh "${target}/share/bash-completion/completions/${name}"
      mv ${prefix}/etc/hub.fish_completion "${target}/share/fish/vendor_completions.d/${name}.fish"
      mv ${prefix}/etc/hub.zsh_completion "${target}/share/zsh/vendor-completions/_${name}"
      rm -rf ${target}/share/doc/hub-doc ${target}/share/vim

  - name: hub-tool
    version: 0.4.5
    check: ${binary} --version | cut -d, -f1 | cut -d' ' -f4 | tr -d v
    tags:
    - docker
    download:
    - url: https://github.com/docker/hub-tool/releases/download/v${version}/hub-tool-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      strip: 1
      files:
      - hub-tool/hub-tool

  - name: ignite
    version: 0.10.0
    check: ${binary} version --output short | tr -d v
    needs:
    - containerd
    - cni
    tags:
    - kvm
    - management
    - vm
    - emulation
    download:
    - url: https://github.com/weaveworks/ignite/releases/download/v${version}/ignite-${alt_arch}
      type: executable
    - url: https://github.com/weaveworks/ignite/releases/download/v${version}/ignited-${alt_arch}
      type: executable
      path: ${target}/bin/ignited
    post_install: |
      echo "Install completion"
      ${binary} completion >"${target}/share/bash-completion/completions/ignite"
      "${target}/bin/ignited" completion >"${target}/share/bash-completion/completions/ignited" || true

  - name: img
    version: 0.5.11
    check: ${binary} --version | cut -d, -f1 | cut -d' ' -f3 | tr -d v
    tags:
    - build
    - oci
    download:
    - url: https://github.com/genuinetools/img/releases/download/v${version}/img-linux-${alt_arch}
      type: executable

  - name: imgcrypt
    version: 1.1.6
    binary: ctr-enc
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    needs:
    - containerd
    - docker
    tags:
    - containerd
    - security
    dockerfile: |
      FROM golang:${go_version}
    install: |
      docker_run \
          --workdir /go/src/github.com/containerd/imgcrypt \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/containerd/imgcrypt .
      sed -i -E 's/ -v / /' Makefile
      sed -i -E "s/ --dirty='.m' / /" Makefile
      make
      make install DESTDIR=/target
      EOF

  - name: imgpkg
    version: 0.30.0
    check: ${binary} version | head -n 1 | cut -d' ' -f3
    tags:
    - oci
    - registry
    - management
    download:
    - url: https://github.com/vmware-tanzu/carvel-imgpkg/releases/download/v${version}/imgpkg-linux-${alt_arch}
      type: executable

  - name: ipfs
    version: 0.14.0
    check: ${binary} version --number
    needs:
    - containerd
    tags:
    - storage
    - network
    - containerd
    download:
    - url: https://github.com/ipfs/go-ipfs/releases/download/v${version}/go-ipfs_v${version}_linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      strip: 1
      files:
      - go-ipfs/ipfs
    files:
    - path: ${prefix}/etc/systemd/system/ipfs.service
      content: |
        [Unit]
        Description=ipfs daemon
        PartOf=containerd

        [Service]
        Environment=IPFS_PATH=/var/lib/ipfs
        ExecStart=/usr/local/bin/ipfs daemon $@
        ExecReload=/bin/kill -s HUP \$MAINPID
        RestartSec=2
        Restart=always
        Type=simple
        KillMode=mixed

        [Install]
        WantedBy=default.target
    - path: ${prefix}/etc/containerd/conf.d/ipfs.toml
      content: |
        ipfs = true
    post_install: |
      echo "Install completion"
      ${binary} commands completion bash >"${target}/share/bash-completion/completions/ipfs"
      IPFS_PATH=${target}/var/lib/ipfs ${binary} init
      IPFS_PATH=${target}/var/lib/ipfs ${binary} config Addresses.API "/ip4/127.0.0.1/tcp/5888"
      IPFS_PATH=${target}/var/lib/ipfs ${binary} config Addresses.Gateway "/ip4/127.0.0.1/tcp/5889"
      echo "Fix systemd units"
      sed -i "s|ExecStart=/usr/local/bin/ipfs|ExecStart=${relative_target}/bin/ipfs|" "${prefix}/etc/systemd/system/ipfs.service"
      if test -z "${prefix}"; then
          if has_systemd; then
              echo "Reload systemd"
              systemctl daemon-reload
          fi
      fi

  - name: iptables
    version: 1.8.8
    binary: ${target}/sbin/iptables
    if: is_rockylinux
    tags:
    - network
    download:
    - url: https://github.com/nicholasdille/centos-iptables-legacy/releases/download/v${version}/iptables-rockylinux8-${alt_arch}.tar.gz
      type: tarball
      path: ${target}

  - name: jp
    version: 0.2.1
    check: ${binary} --version | cut -d' ' -f3
    tags:
    - conversion
    - format
    download:
    - url: https://github.com/jmespath/jp/releases/download/${version}/jp-linux-${alt_arch}
      type: executable

  - name: jwt
    version: 5.0.3
    check: ${binary} --version | cut -d' ' -f2
    needs:
    - docker
    tags:
    - security
    dockerfile: |
      FROM rust:${rust_version}
    install: |
      docker_run \
          --workdir /go/src/github.com/mike-engel/jwt-cli \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "${version}" https://github.com/mike-engel/jwt-cli .
      export RUSTFLAGS='-C target-feature=+crt-static'
      cargo build --release --target x86_64-unknown-linux-gnu
      cp target/x86_64-unknown-linux-gnu/release/jwt /target/bin/
      EOF

  - name: k3d
    version: 5.3.0
    check: ${binary} version | head -n 1 | cut -d' ' -f3 | tr -d v
    needs:
    - docker
    tags:
    - k8s
    - kubernetes
    - docker
    - management
    download:
    - url: https://github.com/rancher/k3d/releases/download/v${version}/k3d-linux-${alt_arch}
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: k3s
    version: 1.23.4+k3s1
    check: ${binary} --version | head -n 1 | cut -d' ' -f3 | tr -d v
    tags:
    - k8s
    - kubernetes
    download:
    - url:
        x86_64: https://github.com/k3s-io/k3s/releases/download/v${version}/k3s
        aarch64: https://github.com/k3s-io/k3s/releases/download/v${version}/k3s-arm64
      type: executable
    files:
    - path: ${prefix}/etc/init.d/k3s
      content: |
        [Unit]
        Description=Lightweight Kubernetes
        Documentation=https://k3s.io
        Wants=network-online.target
        After=network-online.target

        [Install]
        WantedBy=multi-user.target

        [Service]
        Type=notify
        EnvironmentFile=-/etc/default/%N
        EnvironmentFile=-/etc/sysconfig/%N
        KillMode=process
        Delegate=yes
        # Having non-zero Limit*s causes performance problems due to accounting overhead
        # in the kernel. We recommend using cgroups to do container-local accounting.
        LimitNOFILE=1048576
        LimitNPROC=infinity
        LimitCORE=infinity
        TasksMax=infinity
        TimeoutStartSec=0
        Restart=always
        RestartSec=5s
        ExecStartPre=/bin/sh -xc '! /usr/bin/systemctl is-enabled --quiet nm-cloud-setup.service'
        ExecStartPre=-/sbin/modprobe br_netfilter
        ExecStartPre=-/sbin/modprobe overlay
        ExecStart=/usr/local/bin/k3s
    post_install: |
      echo "Fix systemd unit"
      sed -i "s|/usr/local/bin/k3s|${relative_target}/bin/k3s|g" "${prefix}/etc/systemd/system/k3s.service"
      if test -z "${prefix}"; then
          if has_systemd; then
              echo "Reload systemd"
              systemctl daemon-reload
          fi
      fi

  - name: k3sup
    version: 0.11.3
    check: ${binary} version | grep Version | cut -d' ' -f2
    tags:
    - k8s
    - kubernetes
    - management
    download:
    - url:
        x86_64: https://github.com/alexellis/k3sup/releases/download/${version}/k3sup
        aarch64: https://github.com/alexellis/k3sup/releases/download/${version}/k3sup.${alt_arch}
      type: executable

  - name: k9s
    version: 0.25.18
    check: ${binary} version --short | grep "^Version" | cut -dv -f2
    tags:
    - k8s
    - kubernetes
    - management
    - tui
    download:
    - url: https://github.com/derailed/k9s/releases/download/v${version}/k9s_Linux_${arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - k9s

  - name: kapp
    version: 0.51.0
    check: ${binary} version | head -n 1 | cut -d' ' -f3
    tags:
    - k8s
    - kubernetes
    - templating
    - package
    - manager
    download:
    - url: https://github.com/vmware-tanzu/carvel-kapp/releases/download/v${version}/kapp-linux-${alt_arch}
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash | grep -v "^Succeeded$" >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish | grep -v "^Succeeded$" >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh  | grep -v "^Succeeded$" >"${target}/share/zsh/vendor-completions/_${name}"

  - name: kbld
    version: 0.34.0
    check: ${binary} version | head -n 1 | cut -d' ' -f3
    tags:
    - k8s
    - kubernetes
    - build
    download:
    - url: https://github.com/vmware-tanzu/carvel-kbld/releases/download/v${version}/kbld-linux-${alt_arch}
      type: executable

  - name: kbrew
    version: 0.1.0
    check: ${binary} version | cut -d, -f1 | cut -d'"' -f4 | tr -d v
    tags:
    - k8s
    - kubernetes
    - package
    - manager
    download:
    - url: https://github.com/kbrew-dev/kbrew/releases/download/v${version}/kbrew_${version}_Linux_${arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - kbrew

  - name: kind
    version: 0.14.0
    check: ${binary} version | cut -d' ' -f1-2 | cut -d' ' -f2 | tr -d v
    tags:
    - k8s
    - kubernetes
    - docker
    - management
    needs:
    - docker
    download:
    - url: https://github.com/kubernetes-sigs/kind/releases/download/v${version}/kind-linux-${alt_arch}
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: kink
    version: 0.2.1
    check: ${binary} version | grep GitVersion | tr -s ' ' | cut -d' ' -f2
    tags:
    - k8s
    - kubernetes
    - management
    download:
    - url: https://github.com/Trendyol/kink/releases/download/v${version}/kink_${version}_Linux-${arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - kink
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: kompose
    version: 1.26.1
    check: ${binary} version | cut -d' ' -f1
    tags:
    - k8s
    - kubernetes
    - compose
    download:
    - url: https://github.com/kubernetes/kompose/releases/download/v${version}/kompose-linux-${alt_arch}
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: kots
    version: 1.78.0
    binary: kubectl-kots
    check: ${binary} version | cut -d' ' -f3
    download:
    - url: https://github.com/replicatedhq/kots/releases/download/v${version}/kots_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - kots
    post_install: |
      mv "${target}/bin/kots" "${target}/bin/kubectl-kots"
      echo "Install completion"
      ${binary} completion bash 2>/dev/null >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish 2>/dev/null >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh 2>/dev/null >"${target}/share/zsh/vendor-completions/_${name}"

  - name: krew
    version: 0.4.3
    check: ${binary} version 2>/dev/null | grep GitTag | tr -s ' ' | cut -d' ' -f2 | tr -d v
    tags:
    - k8s
    - kubernetes
    - plugin
    - management
    download:
    - url: https://github.com/kubernetes-sigs/krew/releases/download/v${version}/krew-linux_${alt_arch}.tar.gz
      type: tarball
      strip: 1
      path: "${target}/bin"
      files:
      - ./krew-linux_${alt_arch}
    post_install: |
      mv "${target}/bin/krew-linux_${alt_arch}" "${target}/bin/krew"
      echo "Add to path"
      cat >"${prefix}/etc/profile.d/krew.sh" <<"EOF"
      export PATH="${HOME}/.krew/bin:${PATH}"
      EOF
      echo "Install completion"
      ${binary} completion bash 2>/dev/null >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish 2>/dev/null >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh 2>/dev/null >"${target}/share/zsh/vendor-completions/_${name}"

  - name: ktop
    version: 0.3.0
    tags:
    - k8s
    - kubernetes
    - management
    - tui
    download:
    - url: https://github.com/vladimirvivien/ktop/releases/download/v${version}/ktop_v${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - ktop

  - name: kube-bench
    version: 0.6.8
    check: ${binary} version
    tags:
    - k8s
    - kubernetes
    - security
    download:
    - url: https://github.com/aquasecurity/kube-bench/releases/download/v${version}/kube-bench_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: "${target}/bin"
    post_install: |
      mkdir -p "${prefix}/etc/kube-bench"
      mv "${target}/bin/cfg" "${prefix}/etc/kube-bench"
      echo "Install completion"
      ${binary} completion bash 2>/dev/null >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish 2>/dev/null >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh 2>/dev/null >"${target}/share/zsh/vendor-completions/_${name}"

  - name: kubeadm
    version: 1.24.3
    check: ${binary} version --output short | tr -d v
    tags:
    - k8s
    - kubernetes
    - management
    download:
    - url: https://storage.googleapis.com/kubernetes-release/release/v${version}/bin/linux/${alt_arch}/kubeadm
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash 2>/dev/null >"${target}/share/bash-completion/completions/kubeadm"
      ${binary} completion zsh 2>/dev/null >"${target}/share/zsh/vendor-completions/_kubeadm"

  - name: kubeclarity-cli
    version: 2.5.0
    check: ${binary} --version | cut -d' ' -f3
    tags:
    - k8s
    - kubernetes
    - security
    download:
    - url: https://github.com/openclarity/kubeclarity/releases/download/v${version}/kubeclarity-cli-${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: "${target}/bin"
      files:
      - kubeclarity-cli
    post_install: |
      echo "Install completion"
      ${binary} completion bash 2>/dev/null >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish 2>/dev/null >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh 2>/dev/null >"${target}/share/zsh/vendor-completions/_${name}"

  - name: kubectl
    version: 1.24.3
    check: ${binary} version --client --short | cut -d' ' -f3 | tr -d v
    needs:
    - krew
    tags:
    - k8s
    - kubernetes
    - management
    download:
    - url: https://storage.googleapis.com/kubernetes-release/release/v${version}/bin/linux/${alt_arch}/kubectl
      type: executable
    - url: https://dl.k8s.io/release/v${version}/bin/linux/${alt_arch}/kubectl-convert
      type: executable
      path: ${target}/bin/kubectl-convert
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"
      echo "Add alias k"
      cat >"${prefix}/etc/profile.d/kubectl.sh" <<EOF
      alias k=kubectl
      complete -F __start_kubectl k
      EOF
      if test -z "${prefix}" && ( has_tool "krew" || tool_will_be_installed "krew" ); then
          echo "Waiting for krew"
          wait_for_tool "krew"
          echo "Install krew for current user"
          # shellcheck source=/dev/null
          source "${prefix}/etc/profile.d/krew.sh"
          krew update
          krew install krew
          plugins=(
              access-matrix
              advise-policy
              advise-psp
              assert
              blame
              bulk-action
              cert-manager
              cilium
              cyclonus
              debug-shell
              deprecations
              df-pv
              doctor
              edit-status
              emit-event
              evict-pod
              exec-as
              exec-cronjob
              fields
              flame
              fleet
              fuzzy
              gadget
              get-all
              graph
              grep
              hns
              ice
              images
              janitor
              kniff
              konfig
              kubesec-scan
              kurt
              lineage
              modify-secret
              mtail
              neat
              node-shell
              outdated
              pexec
              pod-dive
              pod-inspect
              pod-lens
              rbac-lookup
              rbac-tool
              rbac-view
              reliably
              resource-capacity
              resource-snapshot
              rolesum
              score
              skew
              slice
              sniff
              socks5-proxy
              spy
              sshd
              starboard
              status
              strace
              sudo
              support-bundle
              tap
              trace
              tree
              tunnel
              view-allocations
              view-utilization
              viewnode
              who-can
              whoami
          )
          for plugin in "${plugins[@]}"; do
              echo "Processing ${plugin}"
              if krew list | grep -q "^${plugin}"; then
                  krew update "${plugin}"
              else
                  krew install "${plugin}"
              fi
          done
      else
          warning "kubectl is missing krew. Plugins will not be installed."
          false
      fi

  - name: kubectl-build
    version: 0.1.6
    needs:
    - kubectl
    tags:
    - k8s
    - kubernetes
    - management
    - plugin
    - build
    download:
    - url:
        x86_64: https://github.com/vmware-tanzu/buildkit-cli-for-kubectl/releases/download/v${version}/linux-v${version}.tgz
      type: tarball
      path: ${target}/bin

  - name: kubectl-free
    version: 0.2.0
    check: ${binary} --version | cut -d' ' -f2 | tr -d ','
    needs:
    - kubectl
    tags:
    - k8s
    - kubernetes
    - management
    - plugin
    - analysis
    download:
    - url:
        x86_64: https://github.com/makocchi-git/kubectl-free/releases/download/v${version}/kubectl-free_${version}_Linux_${arch}.zip
      type: zip
      path: ${target}/bin
      files:
      - kubectl-free_${version}_Linux_${arch}/kubectl-free

  - name: kubectl-resources
    version: 0.2.0
    needs:
    - kubectl
    tags:
    - k8s
    - kubernetes
    - management
    - plugin
    - analysis
    download:
    - url: https://github.com/howardjohn/kubectl-resources/releases/download/v${version}/kubectl-resources_${version}_Linux_${arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - kubectl-resources

  - name: kubefire
    version: 0.3.8
    check: ${binary} version | grep "^Version:" | cut -d' ' -f2 | tr -d v
    tags:
    - k8s
    - kubernetes
    - kvm
    - management
    - vm
    - emulation
    download:
    - url: https://github.com/innobead/kubefire/releases/download/v${version}/kubefire-linux-${alt_arch}
      type: executable
    - url: https://github.com/innobead/kubefire/releases/download/v${version}/host-local-rev-linux-${alt_arch}
      type: executable
      path: ${target}/libexec/cni/host-local-rev

  - name: kubelet
    version: 1.24.3
    check: ${binary} --version | cut -d' ' -f2 | tr -d v
    tags:
    - k8s
    - kubernetes
    download:
    - url: https://storage.googleapis.com/kubernetes-release/release/v${version}/bin/linux/${alt_arch}/kubelet
      type: executable

  - name: kubeletctl
    version: 1.8
    check: ${binary} version | grep "^Version:" | cut -d' ' -f2
    tags:
    - k8s
    - kubernetes
    - management
    download:
    - url: https://github.com/cyberark/kubeletctl/releases/download/v${version}/kubeletctl_linux_${alt_arch}
      type: executable

  - name: kubent
    version: 0.5.1
    tags:
    - k8s
    - kubernetes
    - management
    download:
    - url: https://github.com/doitintl/kube-no-trouble/releases/download/${version}/kubent-${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin

  - name: kubesec
    version: 2.11.5
    tags:
    - k8s
    - kubernetes
    - security
    download:
    - url: https://github.com/controlplaneio/kubesec/releases/download/v${version}/kubesec_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - kubesec
    post_install: |
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: kubeswitch
    version: 1.5.0
    tags:
    - k8s
    - kubernetes
    - management
    download:
    - url: https://github.com/danielb42/kubeswitch/releases/download/v${version}/kubeswitch_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - kubeswitch

  - name: kubeval
    version: 0.16.1
    check: ${binary} --version | grep ^Version | cut -d' ' -f2
    tags:
    - k8s
    - kubernetes
    - security
    download:
    - url:
        x86_64: https://github.com/instrumenta/kubeval/releases/download/v0.16.1/kubeval-linux-amd64.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - kubeval

  - name: kustomize
    version: 4.5.7
    check: ${binary} version --short | tr -s ' ' | cut -d' ' -f1 | cut -d/ -f2 | tr -d v
    tags:
    - k8s
    - kubernetes
    - templating
    - management
    download:
    - url: https://github.com/kubernetes-sigs/kustomize/releases/download/kustomize%2Fv${version}/kustomize_v${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: lab
    version: 0.25.1
    check: ${binary} version | cut -d' ' -f3
    tags:
    - development
    download:
    - url: https://github.com/zaquestion/lab/releases/download/v${version}/lab_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - lab
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: lazydocker
    version: 0.18.1
    check: ${binary} --version | grep Version | cut -d' ' -f2
    needs:
    - docker
    tags:
    - docker
    - management
    - tui
    download:
    - url: https://github.com/jesseduffield/lazydocker/releases/download/v${version}/lazydocker_${version}_Linux_${arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - lazydocker

  - name: lazygit
    version: 0.32.2
    check: ${binary} --version | cut -d' ' -f6 | cut -d= -f2 | tr -d ,
    tags:
    - development
    - management
    - tui
    download:
    - url: https://github.com/jesseduffield/lazygit/releases/download/v${version}/lazygit_${version}_Linux_${arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - lazygit

  - name: libcap
    version: 2.65
    binary: ${target}/sbin/setcap
    needs:
    - docker
    tags:
    - kernel
    - caps
    dockerfile: |
      FROM ubuntu:latest
      RUN apt-get update \
       && apt-get -y install --no-install-recommends \
              build-essential \
              git \
              ca-certificates
    install: |
      docker_run \
          --workdir /libcap \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "libcap-${version}" https://git.kernel.org/pub/scm/libs/libcap/libcap.git .
      make -C progs
      make -C progs install FAKEROOT=/target
      cp doc/capsh.1 /target/share/man/man1
      cp doc/getcap.8 /target/share/man/man8
      cp doc/getpcaps.8 /target/share/man/man8
      cp doc/setcap.8 /target/share/man/man8
      EOF

  - name: libcap-ng
    version: 0.8.3
    binary: captest
    needs:
    - docker
    tags:
    - kernel
    - caps
    dockerfile: |
      FROM ubuntu:latest
      RUN apt-get update \
       && apt-get -y install --no-install-recommends \
              git \
              curl \
              ca-certificates \
              autoconf \
              automake \
              libtool \
              build-essential
    install: |
      docker_run \
          --workdir /libcap-ng \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/stevegrubb/libcap-ng .
      ./autogen.sh
      ./configure --prefix=/target --enable-static --disable-shared --without-python
      make LDFLAGS=--static
      make install
      EOF

  - name: libcgroup
    version: 2.0.2
    binary: ${target}/bin/lscgroup
    needs:
    - docker
    tags:
    - kernel
    - cgroup
    dockerfile: |
      FROM ubuntu:latest
      RUN apt-get update \
       && apt-get -y install --no-install-recommends \
              build-essential \
              autoconf \
              automake \
              libtool \
              git \
              ca-certificates \
              m4 \
              bison \
              flex \
              curl
    install: |
      docker_run \
          --workdir /libcgroup \
          <<EOF
      curl -sL https://github.com/libcgroup/libcgroup/releases/download/v${version}/libcgroup-${version}.tar.gz \
      | tar -xz --strip-components 1
      ./configure --prefix=/target --disable-pam --disable-daemon
      make
      make install
      EOF
      cat >/etc/ld.so.conf.d/libcgroup.conf <<EOF
      ${target}/lib
      EOF
      ldconfig

  - name: manifest-tool
    version: 2.0.5
    check: ${binary} --version | cut -d' ' -f3
    tags:
    - docker
    - registry
    download:
    - url: https://github.com/estesp/manifest-tool/releases/download/v${version}/binaries-manifest-tool-${version}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - manifest-tool-linux-${alt_arch}
    post_install: |
      mv "${target}/bin/manifest-tool-linux-${alt_arch}" "${target}/bin/manifest-tool"

  - name: minectl
    version: 0.23.0
    check: ${binary} version | grep ^Version | cut -d' ' -f2
    tags:
    - games
    - management
    download:
    - url: https://github.com/dirien/minectl/releases/download/v${version}/minectl_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - minectl
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: minikube
    version: 1.26.1
    check: ${binary} version | grep "minikube version" | cut -d' ' -f3 | tr -d v
    tags:
    - k8s
    - kubernetes
    - management
    download:
    - url: https://github.com/kubernetes/minikube/releases/download/v${version}/minikube-linux-${alt_arch}
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: mitmproxy
    version: 8.1.1
    tags:
    - network
    download:
    - url:
        x86_64: https://snapshots.mitmproxy.org/${version}/mitmproxy-${version}-linux.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - mitmproxy
      - mitmdump
      - mitmweb

  - name: mutagen
    version: 0.15.0
    check: ${binary} version
    tags:
    - security
    - network
    - storage
    download:
    - url: https://github.com/mutagen-io/mutagen/releases/download/v${version}/mutagen_linux_${alt_arch}_v${version}.tar.gz
      type: tarball
      path: ${target}/bin
    post_install: |
      echo "Install agents"
      mkdir -p "${target}/libexec/mutagen"
      tar -xz \
          --file "${target}/bin/mutagen-agents.tar.gz" \
          --directory "${target}/libexec/mutagen"
      rm "${target}/bin/mutagen-agents.tar.gz"
      echo "Install completion for ${name}"
      ${binary} generate \
          "--bash-completion-script=${target}/share/bash-completion/completions/${name}" \
          "--fish-completion-script=${target}/share/fish/vendor_completions.d/${name}.fish" \
          "--zsh-completion-script=${target}/share/zsh/vendor-completions/_${name}"

  - name: mutagen-compose
    version: 0.14.0-1
    needs:
    - mutagen
    tags:
    - security
    - network
    - storage
    install: |
      curl https://github.com/mutagen-io/mutagen-compose/releases/download/v${version}/mutagen-compose_linux_${alt_arch}_v${version%-*}.tar.gz \
          --silent \
          --location \
      | tar -xz \
          --directory "${target}/bin" \
          --no-same-owner

  - name: nerdctl
    version: 0.22.2
    check: ${binary} --version | cut -d' ' -f3
    tags:
    - containerd
    - rootless
    - management
    download:
    - url: https://github.com/containerd/nerdctl/releases/download/v${version}/nerdctl-${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin

  - name: norouter
    version: 0.6.4
    check: ${binary} --version | cut -d' ' -f3
    tags:
    - network
    download:
    - url: https://github.com/norouter/norouter/releases/download/v${version}/norouter-Linux-${arch}.tgz
      type: tarball
      path: ${target}/bin
      files:
      - norouter

  - name: notation
    version: 0.7.1-alpha.1
    check: ${binary} --version | cut -d' ' -f3
    needs:
    - docker
    tags:
    - docker
    - plugin
    - security
    download:
    - url: https://github.com/notaryproject/notation/releases/download/v${version}/notation_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - notation
    - url: https://github.com/notaryproject/notation/releases/download/v${version}/notation_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/libexec/docker/cli-plugins
      files:
      - docker-generate
      - docker-notation

  - name: nsutils
    version: 0.2
    binary: nslist
    needs:
    - docker
    tags:
    - kernel
    - namespaces
    dockerfile: |
      FROM ubuntu:latest
      RUN apt-get update \
       && apt-get -y install --no-install-recommends \
              git \
              ca-certificates \
              autoconf \
              automake \
              build-essential \
              libcap-dev \
              libbsd-dev \
              libcap2-bin
    install: |
      echo "nsutils ${version}"
      docker_run \
          --workdir /nsutils \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/rd235/nsutils .
      autoreconf -if
      ./configure --prefix=/target
      make LDFLAGS=--static
      mkdir -p \
          /target/share/man/man1
      make install
      EOF

  - name: oci-image-tool
    version: 1.0.0-rc3
    check: ${binary} --version | cut -d' ' -f3
    needs:
    - docker
    tags:
    - oci
    dockerfile: |
      FROM golang:${go_version}
    install: |
      echo "oci-image-tool ${version}"
      docker_run \
          --env GO111MODULE=auto \
          --workdir /go/src/github.com/opencontainers/image-tools \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/opencontainers/image-tools .
      make tool
      cp oci-image-tool /target/bin/
      EOF

  - name: oci-runtime-tool
    version: 0.9.0
    check: ${binary} --version | cut -d, -f1 | cut -d' ' -f3
    needs:
    - docker
    tags:
    - oci
    dockerfile: |
      FROM golang:${go_version}
    install: |
      echo "oci-runtime-tool ${version}"
      docker_run \
          --env GO111MODULE=auto \
          --workdir /go/src/github.com/opencontainers/runtime-tools \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/opencontainers/runtime-tools .
      make tool
      cp oci-runtime-tool /target/bin/
      EOF

  - name: oras
    version: 0.13.0
    check: ${binary} version | head -n 1 | tr -s ' ' | cut -d' ' -f2
    tags:
    - registry
    - storage
    - cnab
    download:
    - url: https://github.com/oras-project/oras/releases/download/v${version}/oras_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - oras

  - name: patat
    version: 0.8.7.0
    tags:
    - markdown
    download:
    - url: https://github.com/jaspervdj/patat/releases/download/v${version}/patat-v${version}-linux-${arch}.tar.gz
      type: tarball
      path: ${target}/bin
      strip: 1
      files:
      - patat-v${version}-linux-${arch}/patat
    - url: https://github.com/jaspervdj/patat/releases/download/v${version}/patat-v${version}-linux-${arch}.tar.gz
      type: tarball
      path: ${target}/share/man/man1
      strip: 1
      files:
      - patat-v${version}-linux-${arch}/patat.1

  - name: podman
    version: 4.1.1
    check: ${binary} --version | cut -d' ' -f3
    needs:
    - conmon
    - runc
    - cni
    - fuse-overlayfs
    - shortnames
    tags:
    - runtime
    - redhat
    - oci
    download:
    - url:
        x86_64: https://github.com/nicholasdille/podman-static/releases/download/v${version}/podman-${alt_arch}.tar.gz
      type: tarball
      path: ${target}
    - url: https://github.com/containers/podman/raw/v${version}/contrib/systemd/system/podman.service.in
      type: file
      path: ${prefix}/etc/systemd/system/podman.service
    - url: https://github.com/containers/podman/raw/v${version}/contrib/systemd/system/podman.socket
      type: file
      path: ${prefix}/etc/systemd/system/podman.socket
    - url: https://github.com/containers/podman/raw/v${version}/contrib/systemd/system/podman-docker.conf
      type: file
      path: ${target}/lib/tmpfiles.d/podman-docker.conf
    post_install: |
      echo "Fix systemd unit"
      sed -i "s|@@PODMAN@@|ExecStart=${relative_target}/bin/podman|" "${prefix}/etc/systemd/system/podman.service"
      if test -z "${prefix}"; then
          if has_systemd; then
              systemctl daemon-reload
          fi
      fi

  - name: podman-docker-shim
    version: 0.1.0
    needs:
    - podman
    tags:
    - runtime
    - redhat
    - oci
    files:
    - path: ${target}/libexec/podman/docker
      content: |
        #!/bin/bash

        exec podman "$@"
    post_install: |
      echo "Fix permissions"
      chmod +x "${target}/libexec/podman/docker"
      if ! tool_will_be_installed "docker"; then
          ln -sf "${target}/libexec/podman/docker" "${target}/bin/docker"
      fi

  - name: podman-tui
    version: 0.5.0
    check: ${binary} version | cut -d' ' -f2 | tr -d v
    needs:
    - podman
    tags:
    - rootless
    - network
    dockerfile: |
      FROM docker.io/library/golang:${go_version}
      RUN mkdir -p /go/src/github.com/containers/podman-tui
    install: |
      docker_run \
          --workdir /go/src/github.com/containers/podman-tui \
          --env CGO_ENABLED=0 \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/containers/podman-tui .
      go build -mod=vendor -o ./bin/linux/podman-tui -tags "containers_image_openpgp remote"
      cp ./bin/linux/podman-tui /target/bin/
      EOF

  - name: polaris
    version: 7.0.1
    tags:
    - k8s
    - kubernetes
    download:
    - url: https://github.com/FairwindsOps/polaris/releases/download/${version}/polaris_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - polaris

  - name: portainer
    version: 2.14.2
    check: ${binary} --version 2>&1
    needs:
    - docker
    - docker-compose-v1
    tags:
    - docker
    - k8s
    - kubernetes
    - management
    download:
    - url: https://github.com/portainer/portainer/releases/download/${version}/portainer-${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      strip: 1
      files:
      - portainer/portainer
    - url: https://github.com/portainer/portainer/releases/download/${version}/portainer-${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/share/portainer
      strip: 1
      files:
      - portainer/public
    files:
    - path: ${prefix}/etc/systemd/system/portainer.service
      content: |
        [Unit]
        Description=portainer
        Documentation=https://www.portainer.io/
        After=network.target local-fs.target

        [Service]
        ExecStart=/usr/local/bin/portainer --assets=${TARGET}/share/portainer --data=${TARGET}/lib/portainer --bind=127.0.0.1:9000 --bind-https=127.0.0.1:9443 --tunnel-addr=127.0.0.1

        Type=exec
        Delegate=yes
        KillMode=process
        Restart=always
        RestartSec=5
        # Having non-zero Limit*s causes performance problems due to accounting overhead
        # in the kernel. We recommend using cgroups to do container-local accounting.
        LimitNPROC=infinity
        LimitCORE=infinity
        LimitNOFILE=1048576
        # Comment TasksMax if your systemd version does not supports it.
        # Only systemd 226 and above support this version.
        TasksMax=infinity

        [Install]
        WantedBy=multi-user.target
    - path: ${prefix}/etc/init.d/portainer
      content: |
        #!/bin/sh
        set -e

        ### BEGIN INIT INFO
        # Provides:           portainer
        # Required-Start:     $syslog $remote_fs
        # Required-Stop:      $syslog $remote_fs
        # Should-Start:       cgroupfs-mount cgroup-lite
        # Should-Stop:        cgroupfs-mount cgroup-lite
        # Default-Start:      2 3 4 5
        # Default-Stop:       0 1 6
        # Short-Description:  Create lightweight, portable, self-sufficient containers.
        # Description:
        #  Docker is an open-source project to easily create lightweight, portable,
        #  self-sufficient containers from any application. The same container that a
        #  developer builds and tests on a laptop can run at scale, in production, on
        #  VMs, bare metal, OpenStack clusters, public clouds and more.
        ### END INIT INFO

        export PATH=/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/sbin:/usr/local/bin

        BASE=portainer

        # modify these in /etc/default/$BASE (/etc/default/portainer)
        PORTAINER=/usr/local/bin/portainer
        # This is the pid file created/managed by start-stop-daemon
        PORTAINER_SSD_PIDFILE=/var/run/$BASE-ssd.pid
        PORTAINER_LOGFILE=/var/log/$BASE.log
        PORTAINER_DESC="Portainer"

        # Get lsb functions
        . /lib/lsb/init-functions

        if [ -f /etc/default/$BASE ]; then
          . /etc/default/$BASE
        fi

        # Check portainer is present
        if [ ! -x $PORTAINER ]; then
          log_failure_msg "$PORTAINER not present or not executable"
          exit 1
        fi

        check_init() {
          # see also init_is_upstart in /lib/lsb/init-functions (which isn't available in Ubuntu 12.04, or we'd use it directly)
          if [ -x /sbin/initctl ] && /sbin/initctl version 2> /dev/null | grep -q upstart; then
            log_failure_msg "$PORTAINER_DESC is managed via upstart, try using service $BASE $1"
            exit 1
          fi
        }

        fail_unless_root() {
          if [ "$(id -u)" != '0' ]; then
            log_failure_msg "$PORTAINER_DESC must be run as root"
            exit 1
          fi
        }

        cgroupfs_mount() {
          # see also https://github.com/tianon/cgroupfs-mount/blob/master/cgroupfs-mount
          if grep -v '^#' /etc/fstab | grep -q cgroup \
            || [ ! -e /proc/cgroups ] \
            || [ ! -d /sys/fs/cgroup ]; then
            return
          fi
          if ! mountpoint -q /sys/fs/cgroup; then
            mount -t tmpfs -o uid=0,gid=0,mode=0755 cgroup /sys/fs/cgroup
          fi
          (
            cd /sys/fs/cgroup
            for sys in $(awk '!/^#/ { if ($4 == 1) print $1 }' /proc/cgroups); do
              mkdir -p $sys
              if ! mountpoint -q $sys; then
                if ! mount -n -t cgroup -o $sys cgroup $sys; then
                  rmdir $sys || true
                fi
              fi
            done
          )
        }

        case "$1" in
          start)
            check_init

            fail_unless_root

            cgroupfs_mount

            touch "$PORTAINER_LOGFILE"

            ulimit -n 1048576

            # Having non-zero limits causes performance problems due to accounting overhead
            # in the kernel. We recommend using cgroups to do container-local accounting.
            if [ "$BASH" ]; then
              ulimit -u unlimited
            else
              ulimit -p unlimited
            fi

            log_begin_msg "Starting $PORTAINER_DESC: $BASE"
            start-stop-daemon --start --background \
              --no-close \
              --exec "$PORTAINER" \
              --pidfile "$PORTAINER_SSD_PIDFILE" \
              --make-pidfile \
              -- \
              >> "$PORTAINER_LOGFILE" 2>&1
            log_end_msg $?
            ;;

          stop)
            check_init
            fail_unless_root
            if [ -f "$PORTAINER_SSD_PIDFILE" ]; then
              log_begin_msg "Stopping $PORTAINER_DESC: $BASE"
              start-stop-daemon --stop --pidfile "$PORTAINER_SSD_PIDFILE" --retry 10
              log_end_msg $?
            else
              log_warning_msg "Docker already stopped - file $PORTAINER_SSD_PIDFILE not found."
            fi
            ;;

          restart)
            check_init
            fail_unless_root
            portainer_pid=$(cat "$PORTAINER_SSD_PIDFILE" 2> /dev/null)
            [ -n "$portainer_pid" ] \
              && ps -p $portainer_pid > /dev/null 2>&1 \
              && $0 stop
            $0 start
            ;;

          force-reload)
            check_init
            fail_unless_root
            $0 restart
            ;;

          status)
            check_init
            status_of_proc -p "$PORTAINER_SSD_PIDFILE" "$PORTAINER" "$PORTAINER_DESC"
            ;;

          *)
            echo "Usage: service portainer {start|stop|restart|status}"
            exit 1
            ;;
        esac
    post_install: |
      echo "Install dedicated docker-compose v1"
      cp "${target}/bin/docker-compose" "${target}/share/portainer/docker-compose"
      echo "Fix systemd unit"
      sed -i "s|/usr/local/bin/portainer|${relative_target}/bin/portainer|g" "${prefix}/etc/systemd/system/portainer.service"
      echo "Fix init script"
      sed -i "s|/usr/local/bin/portainer|${relative_target}/bin/portainer|g" "${prefix}/etc/init.d/portainer"
      chmod +x "${prefix}/etc/init.d/portainer"
      if test -z "${prefix}"; then
          if has_systemd; then
              echo "Reload systemd"
              systemctl daemon-reload
          fi
      fi

  - name: porter
    version: 0.38.12
    check: ${binary} --version | cut -d' ' -f2 | tr -d v
    tags:
    - cnab
    download:
    - url: https://github.com/getporter/porter/releases/download/v${version}/porter-linux-${alt_arch}
      type: executable
    post_install: |
      if test -z "${prefix}"; then
          echo "Install mixins"
          ${binary} mixin install exec
          ${binary} mixin install docker
          ${binary} mixin install docker-compose
          ${binary} mixin install kubernetes
          echo "Install plugins"
          ${binary} plugins install kubernetes
      fi

  - name: qemu
    version: 7.0.0
    binary: qemu-img
    check: ${binary} --version | grep qemu-img | cut -d' ' -f3
    tags:
    - vm
    - emulation
    download:
    - url: https://github.com/nicholasdille/qemu-static/releases/download/v${version}/qemu-${alt_arch}.tar.gz
      type: tarball
      strip: 2
      path: ${target}

  - name: regclient
    version: 0.4.4
    binary: regctl
    check: ${binary} version | jq -r .VCSTag | tr -d v
    tags:
    - registry
    - management
    download:
    - url: https://github.com/regclient/regclient/releases/download/v${version}/regctl-linux-${alt_arch}
      type: executable
      path: ${target}/bin/regctl
    - url: https://github.com/regclient/regclient/releases/download/v${version}/regbot-linux-${alt_arch}
      type: executable
      path: ${target}/bin/regbot
    - url: https://github.com/regclient/regclient/releases/download/v${version}/regsync-linux-${alt_arch}
      type: executable
      path: ${target}/bin/regsync
    post_install: |
      echo "Install completion for regctl"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"
      echo "Install completion for regbot"
      "${target}/bin/regbot" completion bash >"${target}/share/bash-completion/completions/regbot"
      "${target}/bin/regbot" completion fish >"${target}/share/fish/vendor_completions.d/regbot.fish"
      "${target}/bin/regbot" completion zsh >"${target}/share/zsh/vendor-completions/_regbot"
      echo "Install completion for regsync"
      "${target}/bin/regsync" completion bash >"${target}/share/bash-completion/completions/regsync"
      "${target}/bin/regsync" completion fish >"${target}/share/fish/vendor_completions.d/regsync.fish"
      "${target}/bin/regsync" completion zsh >"${target}/share/zsh/vendor-completions/_regsync"

  - name: rekor
    version: 0.10.0
    binary: rekor-cli
    check: ${binary} version 2>&1 | grep ^GitVersion | cut -dv -f2
    tags:
    - security
    download:
    - url: https://github.com/sigstore/rekor/releases/download/v${version}/rekor-cli-linux-${alt_arch}
      type: executable
      path: ${target}/bin/rekor-cli
    - url: https://github.com/sigstore/rekor/releases/download/v${version}/rekor-server-linux-${alt_arch}
      type: executable
      path: ${target}/bin/rekor-server
    post_install: |
      echo "Install completion for rekor-cli"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"
      echo "Install completion for rekor-server"
      "${target}/bin/rekor-server" completion bash >"${target}/share/bash-completion/completions/rekor-server"
      "${target}/bin/rekor-server" completion fish >"${target}/share/fish/vendor_completions.d/rekor-server.fish"
      "${target}/bin/rekor-server" completion zsh >"${target}/share/zsh/vendor-completions/_rekor-server"

  - name: rootlesskit
    version: 1.0.1
    check: ${binary} --version | cut -d' ' -f3
    tags:
    - rootless
    download:
    - url: https://github.com/rootless-containers/rootlesskit/releases/download/v${version}/rootlesskit-${arch}.tar.gz
      type: tarball
      path: ${target}/bin

  - name: runc
    version: 1.1.3
    check: ${binary} --version | head -n 1 | cut -d' ' -f3
    needs:
    - go-md2man
    tags:
    - runtime
    - oci
    download:
    - url: https://github.com/opencontainers/runc/releases/download/v${version}/runc.${alt_arch}
      type: executable
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-checkpoint.8.md
      type: file
      path: ${target}/share/man/man8/runc-checkpoint.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-create.8.md
      type: file
      path: ${target}/share/man/man8/runc-create.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-delete.8.md
      type: file
      path: ${target}/share/man/man8/runc-delete.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-events.8.md
      type: file
      path: ${target}/share/man/man8/runc-events.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-exec.8.md
      type: file
      path: ${target}/share/man/man8/runc-exec.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-kill.8.md
      type: file
      path: ${target}/share/man/man8/runc-kill.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-list.8.md
      type: file
      path: ${target}/share/man/man8/runc-list.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-pause.8.md
      type: file
      path: ${target}/share/man/man8/runc-pause.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-ps.8.md
      type: file
      path: ${target}/share/man/man8/runc-ps.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-restore.8.md
      type: file
      path: ${target}/share/man/man8/runc-restore.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-resume.8.md
      type: file
      path: ${target}/share/man/man8/runc-resume.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-run.8.md
      type: file
      path: ${target}/share/man/man8/runc-run.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-spec.8.md
      type: file
      path: ${target}/share/man/man8/runc-spec.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-start.8.md
      type: file
      path: ${target}/share/man/man8/runc-start.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-state.8.md
      type: file
      path: ${target}/share/man/man8/runc-state.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc-update.8.md
      type: file
      path: ${target}/share/man/man8/runc-update.8.md
    - url: https://github.com/opencontainers/runc/raw/v${version}/man/runc.8.md
      type: file
      path: ${target}/share/man/man8/runc.8.md
    post_install: |
      find "${target}/share/man/man8" -type f -name \*.md \
      | while read FILE; do
          DEST_FILE="$(basename "${FILE}" .md)"
          DEST_DIR="$(dirname "${FILE}")"
          DEST="${DEST_DIR}/${DEST_FILE}"
          echo "Converting ${FILE} to ${DEST}"
          go-md2man -in "${FILE}" -out "${DEST}"
          rm "${FILE}"
      done

  - name: scorecard
    version: 4.5.0
    check: ${binary} version | grep "GitVersion" | cut -dv -f2
    tags:
    - security
    download:
    - url: https://github.com/ossf/scorecard/releases/download/v${version}/scorecard_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - scorecard-linux-${alt-arch}
    post_install: |
      echo "Rename binary"
      mv "${target}/bin/scorecard-linux-${alt_arch}" "${target}/bin/scorecard"
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: shortnames
    version: 2022.02.08
    binary: false
    tags:
    - redhat
    download:
    - url: https://github.com/containers/shortnames/raw/v${version}/shortnames.conf
      type: file
      path: ${prefix}/etc/containers/registries.conf.d/00-shortnames.conf

  - name: skopeo
    version: 1.9.2
    check: ${binary} --version | cut -d' ' -f3
    tags:
    - registry
    - redhat
    - oci
    download:
    - url:
        x86_64: https://github.com/nicholasdille/skopeo-static/releases/download/v${version}/skopeo-${alt_arch}.tar.gz
      type: tarball
      path: ${target}

  - name: slirp4netns
    version: 1.2.0
    check: ${binary} --version | head -n 1 | cut -d' ' -f3
    tags:
    - rootless
    - network
    download:
    - url: https://github.com/rootless-containers/slirp4netns/releases/download/v${version}/slirp4netns-${arch}
      type: executable
    - url: https://github.com/rootless-containers/slirp4netns/raw/v1.2.0/slirp4netns.1
      type: file
      path: ${target}/share/man/man1/slirp4netns.1

  - name: sops
    version: 3.7.3
    check: ${binary} --version | head -n 1 | cut -d' ' -f2
    tags:
    - security
    download:
    - url:
        x86_64: https://github.com/mozilla/sops/releases/download/v${version}/sops-v${version}.linux
      type: executable

  - name: sshocker
    version: 0.3.0
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    tags:
    - security
    - network
    - storage
    download:
    - url: https://github.com/lima-vm/sshocker/releases/download/v${version}/sshocker-Linux-${arch}
      type: executable

  - name: stargz-snapshotter
    version: 0.12.0
    binary: containerd-stargz-grpc
    check: ${binary} -version | cut -d' ' -f2 | tr -d v
    needs:
    - containerd
    tags:
    - containerd
    - storage
    download:
    - url: https://github.com/containerd/stargz-snapshotter/releases/download/v${version}/stargz-snapshotter-v${version}-linux-${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
    files:
    - path: "${prefix}/etc/systemd/system/stargz-snapshotter.service"
      content: |
        [Unit]
        Description=stargz snapshotter
        PartOf=containerd

        [Service]
        Environment=IPFS_PATH=${XDG_DATA_HOME}/ipfs
        ExecStart=/usr/local/bin/containerd-stargz-grpc -address "${XDG_RUNTIME_DIR}/containerd-stargz-grpc/containerd-stargz-grpc.sock" -root "${XDG_DATA_HOME}/containerd-stargz-grpc" -config "${XDG_CONFIG_HOME}/containerd-stargz-grpc/config.toml"
        ExecReload=/bin/kill -s HUP \$MAINPID
        RestartSec=2
        Restart=always
        Type=simple
        KillMode=mixed

        [Install]
        WantedBy=default.target
    - path:
      content: |
        version = 2

        # Plug stargz snapshotter into containerd
        # Containerd recognizes stargz snapshotter through specified socket address.
        # The specified address below is the default which stargz snapshotter listen to.
        [proxy_plugins]
          [proxy_plugins.stargz]
            type = "snapshot"
            address = "/run/containerd-stargz-grpc/containerd-stargz-grpc.sock"

        # Use stargz snapshotter through CRI
        [plugins."io.containerd.grpc.v1.cri".containerd]
          snapshotter = "stargz"
          disable_snapshot_annotations = false
    post_install: |
      echo "Install systemd units"
      sed -i "s|ExecStart=/usr/local/bin/containerd-stargz-grpc|ExecStart=${relative_target}/bin/containerd-stargz-grpc|" "${prefix}/etc/systemd/system/stargz-snapshotter.service"
      if test -z "${prefix}"; then
          if has_systemd; then
              echo "Reload systemd"
              systemctl daemon-reload
          fi
      fi

  - name: stern
    version: 1.21.0
    check: ${binary} --version | grep ^version | cut -d' ' -f2
    tags:
    - k8s
    - kubernetes
    - debugging
    - analysis
    download:
    - url: https://github.com/stern/stern/releases/download/v${version}/stern_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - stern
    post_install: |
      echo "Install completion"
      ${binary} --completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} --completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} --completion zsh  >"${target}/share/zsh/vendor-completions/_${name}"

  - name: switcher
    version: 0.7.1
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    tags:
    - k8s
    - kubernetes
    - management
    download:
    - url:
        x86_64: https://github.com/danielfoehrKn/kubeswitch/releases/download/${version}/switcher_linux_${alt_arch}
      type: executable
    - url: https://github.com/danielfoehrKn/kubeswitch/releases/download/${version}/switch.sh
      type: executable
      path: ${target}/bin/switch.sh
    - url: https://github.com/danielfoehrKn/kubeswitch/raw/0.7.1/scripts/_switch.bash
      type: file
      path: ${target}/share/bash-completion/completions/${name}

  - name: syft
    version: 0.53.4
    check: ${binary} --version | cut -d' ' -f2
    tags:
    - sbom
    - security
    download:
    - url: https://github.com/anchore/syft/releases/download/v${version}/syft_${version}_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - syft
    post_install: |
      echo "Install completion"
      ${binary} completion bash | sed -E 's/^(\s*complete.*)/\1 syft/'            >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish | sed -E 's/complete -c  -e/complete -c syft -e/' >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh                                                    >"${target}/share/zsh/vendor-completions/_${name}"

  - name: task
    version: 3.14.1
    check: ${binary} --version | cut -d' ' -f3 | tr -d v
    tags:
    - development
    download:
    - url: https://github.com/go-task/task/releases/download/v${version}/task_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - task
    - url: https://github.com/go-task/task/releases/download/v${version}/task_linux_${alt_arch}.tar.gz
      type: tarball
      path: ${target}/share
      strip: 2
      files:
      - completion/bash/task.bash
      - completion/fish/task.fish
      - completion/zsh/_task
    post_install: |
      mv "${target}/share/${name}.bash" "${target}/share/bash-completion/completions/${name}"
      mv "${target}/share/${name}.fish" "${target}/share/fish/vendor_completions.d/${name}.fish"
      mv "${target}/share/_${name}" "${target}/share/zsh/vendor-completions/_${name}"

  - name: trivy
    version: 0.30.4
    check: ${binary} --version | cut -d' ' -f2
    tags:
    - security
    - analysis
    download:
    - url:
        x86_64: https://github.com/aquasecurity/trivy/releases/download/v${version}/trivy_${version}_Linux-64bit.tar.gz
        aarch64: https://github.com/aquasecurity/trivy/releases/download/v${version}/trivy_${version}_Linux-ARM64.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - trivy

  - name: uidmap
    version: 4.11.1
    binary: newuidmap
    needs:
    - docker
    tags:
    - kernel
    dockerfile: |
      FROM ubuntu:latest
      RUN apt-get update \
       && apt-get -y install --no-install-recommends \
              curl \
              ca-certificates \
              xz-utils \
              build-essential
    install: |
      docker_run \
          --env DEBIAN_FRONTEND=noninteractive \
          --workdir /uidmap \
          <<EOF
      curl -sL https://github.com/shadow-maint/shadow/releases/download/v${version}/shadow-${version}.tar.xz \
      | tar -xJ --strip-components 1
      ./configure --prefix=/target --enable-static --disable-shared
      make LDFLAGS=--static
      mkdir -p \
          /target/bin \
          /target/share/man/man1
      cp src/newuidmap /target/bin
      cp src/newgidmap /target/bin
      cp man/man1/newuidmap.1 /target/share/man/man1
      cp man/man1/newgidmap.1 /target/share/man/man1
      EOF

  - name: umoci
    version: 0.4.7
    check: ${binary} --version | cut -d' ' -f3
    tags:
    - oci
    download:
    - url: https://github.com/opencontainers/umoci/releases/download/v${version}/umoci.${alt_arch}
      type: executable

  - name: util-linux
    version: 2.38.1
    binary: lsns
    needs:
    - docker
    tags:
    - kernel
    - namespaces
    dockerfile: |
      FROM ubuntu:latest
      ENV DEBIAN_FRONTEND=noninteractive
      RUN apt-get update \
       && apt-get -y install --no-install-recommends \
              git \
              ca-certificates \
              autoconf \
              automake \
              autopoint \
              gettext \
              bison \
              libtool \
              pkg-config \
              make \
              asciidoctor
    install: |
      docker_run \
          --workdir /util-linux \
          <<EOF
      git clone -q --config advice.detachedHead=false --depth 1 --branch "v${version}" https://github.com/util-linux/util-linux .
      ./autogen.sh
      ./configure --disable-shared
      make LDFLAGS=--static
      mkdir -p \
          /target/bin \
          /target/share/man/man1 \
          /target/share/man/man8 \
          /target/share/bash-completion/completions
      cp lsns nsenter unshare /target/bin
      cp \
          sys-utils/nsenter.1 sys-utils/unshare.1 \
          /target/share/man/man1/
      cp sys-utils/lsns.8 /target/share/man/man8/
      cp \
          bash-completion/lsns bash-completion/nsenter bash-completion/unshare \
          /target/share/bash-completion/completions
      EOF

  - name: vendir
    version: 0.29.0
    check: ${binary} version | head -n 1 | cut -d' ' -f3
    tags:
    - development
    download:
    - url: https://github.com/vmware-tanzu/carvel-vendir/releases/download/v${version}/vendir-linux-${alt_arch}
      type: executable

  - name: watchtower
    version: 1.4.0
    needs:
    - docker
    tags:
    - docker
    - management
    download:
    - url:
        x86_64: https://github.com/containrrr/watchtower/releases/download/v1.4.0/watchtower_linux_amd64.tar.gz
        aarch64: https://github.com/containrrr/watchtower/releases/download/v1.4.0/watchtower_linux_arm64v8.tar.gz
      type: tarball
      path: ${target}/bin
      files:
      - watchtower

  - name: webhookd
    version: 1.15.0
    tags:
    - development
    download:
    - url: https://github.com/ncarlier/webhookd/releases/download/v${version}/webhookd-linux-${alt_arch}.tgz
      type: tarball
      path: ${target}/bin
      files:
      - webhookd

  - name: win-gpg-agent
    version: 1.6.3
    binary: sorelay.exe
    check: ${binary} --version 2>&1 | tail -n 1 | cut -d' ' -f1'
    tags:
    - wsl
    download:
    - url:
        x86_64: https://github.com/rupor-github/win-gpg-agent/releases/download/v${version}/win-gpg-agent.zip
      type: zip
      path: ${target}/bin
      files:
      - sorelay.exe

  - name: ytt
    version: 0.42.0
    check: ${binary} version | cut -d' ' -f3
    tags:
    - k8s
    - kubernetes
    - templating
    - package
    - manager
    download:
    - url: https://github.com/vmware-tanzu/carvel-ytt/releases/download/v${version}/ytt-linux-${alt_arch}
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: yq
    version: 4.27.2
    check: ${binary} --version | cut -d' ' -f4
    tags:
    - conversion
    - format
    download:
    - url: https://github.com/mikefarah/yq/releases/download/v${version}/yq_linux_${alt_arch}
      type: executable
    post_install: |
      echo "Install completion"
      ${binary} shell-completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} shell-completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} shell-completion zsh >"${target}/share/zsh/vendor-completions/_${name}"

  - name: zot
    version: 1.4.1
    tags:
    - registry
    - image
    - oci
    download:
    - url: https://github.com/project-zot/zot/releases/download/v${version}/zot-linux-${alt_arch}
      type: executable
    - url: https://github.com/project-zot/zot/releases/download/v${version}/zli-linux-${alt_arch}
      type: executable
      path: ${target}/bin/zli
    - url: https://github.com/project-zot/zot/releases/download/v${version}/zb-linux-${alt_arch}
      type: executable
      path: ${target}/bin/zb
    - url: https://github.com/project-zot/zot/releases/download/v${version}/zxp-linux-${alt_arch}
      type: executable
      path: ${target}/bin/zxp
    post_install: |
      echo "Install completion"
      ${binary} shell-completion bash >"${target}/share/bash-completion/completions/${name}"
      ${binary} shell-completion fish >"${target}/share/fish/vendor_completions.d/${name}.fish"
      ${binary} shell-completion zsh >"${target}/share/zsh/vendor-completions/_${name}"
      zli shell-completion bash >"${target}/share/bash-completion/completions/zli"
      zli shell-completion fish >"${target}/share/fish/vendor_completions.d/zli.fish"
      zli shell-completion zsh >"${target}/share/zsh/vendor-completions/_zli"
      zxp shell-completion bash >"${target}/share/bash-completion/completions/zxp"
      zxp shell-completion fish >"${target}/share/fish/vendor_completions.d/zxp.fish"
      zxp shell-completion zsh >"${target}/share/zsh/vendor-completions/_zxp"
